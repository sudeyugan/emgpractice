import streamlit as st
import os
import tensorflow as tf
import time
from tensorflow.keras.callbacks import Callback

# è·å–æ‰€æœ‰å¯è§çš„ç‰©ç† GPU è®¾å¤‡
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        # è®¾ç½®æ˜¾å­˜æŒ‰éœ€å¢é•¿
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("å·²å¼€å¯æ˜¾å­˜æŒ‰éœ€å¢é•¿æ¨¡å¼")
    except RuntimeError as e:
        print(e)
import glob
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import GroupShuffleSplit
from tensorflow.keras.callbacks import ReduceLROnPlateau

# å¼•å…¥æˆ‘ä»¬è‡ªå®šä¹‰çš„æ¨¡å—
import data_loader
from model import build_simple_cnn, build_advanced_crnn


class StreamlitKerasCallback(Callback):
    """
    ç”¨äºè¿æ¥ Keras è®­ç»ƒè¿‡ç¨‹ä¸ Streamlit è¿›åº¦æ¡çš„è‡ªå®šä¹‰å›è°ƒ
    """
    def __init__(self, total_epochs, progress_bar, status_text):
        super().__init__()
        self.total_epochs = total_epochs
        self.progress_bar = progress_bar
        self.status_text = status_text
        self.start_time = None

    def on_train_begin(self, logs=None):
        self.start_time = time.time()
        self.progress_bar.progress(0)
        self.status_text.text("ğŸš€ å‡†å¤‡å¼€å§‹è®­ç»ƒ...")

    def on_epoch_end(self, epoch, logs=None):
        # epoch æ˜¯ä» 0 å¼€å§‹çš„ä¸‹æ ‡ï¼Œæ‰€ä»¥ +1
        current_epoch = epoch + 1
        
        # 1. æ›´æ–°è¿›åº¦æ¡ (é˜²æ­¢ EarlyStopping å¯¼è‡´æ¯”ä¾‹æº¢å‡ºï¼Œé™åˆ¶åœ¨ 0-1 ä¹‹é—´)
        progress = min(current_epoch / self.total_epochs, 1.0)
        self.progress_bar.progress(progress)
        
        # 2. è®¡ç®—æ—¶é—´
        elapsed_time = time.time() - self.start_time
        avg_time_per_epoch = elapsed_time / current_epoch
        remaining_epochs = self.total_epochs - current_epoch
        eta_seconds = avg_time_per_epoch * remaining_epochs
        
        # æ ¼å¼åŒ–æ—¶é—´å­—ç¬¦ä¸²
        eta_str = time.strftime("%M:%S", time.gmtime(eta_seconds))
        elapsed_str = time.strftime("%M:%S", time.gmtime(elapsed_time))
        
        # 3. è·å–æŒ‡æ ‡ (Loss & Accuracy)
        loss = logs.get('loss', 0)
        acc = logs.get('accuracy', 0)
        val_loss = logs.get('val_loss', 0)
        val_acc = logs.get('val_accuracy', 0)
        
        # 4. æ›´æ–°çŠ¶æ€æ–‡æœ¬
        status_msg = (
            f"Epoch {current_epoch}/{self.total_epochs} | "
            f"â³ å‰©ä½™: {eta_str} (å·²ç”¨: {elapsed_str}) | "
            f"Loss: {loss:.4f} Acc: {acc:.1%} | "
            f"Val Loss: {val_loss:.4f} Val Acc: {val_acc:.1%}"
        )
        self.status_text.text(status_msg)

    def on_train_end(self, logs=None):
        # è®­ç»ƒç»“æŸï¼ˆåŒ…æ‹¬æ—©åœï¼‰ï¼Œå°†è¿›åº¦æ¡æ‹‰æ»¡å¹¶æç¤º
        self.progress_bar.progress(100)
        self.status_text.text("âœ… è®­ç»ƒå·²å®Œæˆï¼")

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',    # ç›‘æ§éªŒè¯é›†çš„æŸå¤±å€¼
    factor=0.2,             # å­¦ä¹ ç‡è°ƒæ•´å€æ•°ï¼šå½“è§¦å‘æ—¶ï¼Œæ–°å­¦ä¹ ç‡ = æ—§å­¦ä¹ ç‡ * 0.5
    patience=5,             # è€å¿ƒå€¼ï¼šå¦‚æœè¿ç»­ 5 ä¸ª epoch éªŒè¯é›†æŸå¤±éƒ½æ²¡æœ‰æ”¹å–„ï¼Œåˆ™è§¦å‘
    min_lr=1e-6,            # å­¦ä¹ ç‡ä¸‹é™ï¼šé˜²æ­¢å­¦ä¹ ç‡è¢«å‡åˆ°è¿‡å°
    verbose=1               # è§¦å‘æ—¶åœ¨ç»ˆç«¯æ‰“å°æ¶ˆæ¯
)

st.set_page_config(layout="wide", page_title="EMG è®­ç»ƒå·¥ä½œç«™")
if 'trained_model' not in st.session_state:
    st.session_state['trained_model'] = None
if 'train_history' not in st.session_state:
    st.session_state['train_history'] = None

# ================= 1. æ–‡ä»¶æ‰«æé€»è¾‘ =================
@st.cache_data
def scan_data_folder(root_dir):
    """æ‰«ææ–‡ä»¶å¤¹ï¼Œæ„å»º Subject -> Date -> Labels ç»“æ„"""
    structure = {}
    file_map = {} # å­˜å‚¨ label -> file_path listï¼Œç”¨äºå¿«é€Ÿæ£€ç´¢
    
    # æŸ¥æ‰¾æ‰€æœ‰ RAW_EMG æ–‡ä»¶
    pattern = os.path.join(root_dir, "*", "*", "RAW_EMG*.csv")
    files = glob.glob(pattern)
    
    for f in files:
        subject, date, label, fname = data_loader.parse_filename_info(f)
        if label is None: continue
        
        if subject not in structure: structure[subject] = {}
        if date not in structure[subject]: structure[subject][date] = set()
        
        structure[subject][date].add(label)
        
        # æ„å»ºç´¢å¼•é”®
        key = (subject, date, label)
        if key not in file_map: file_map[key] = []
        file_map[key].append(f)
        
    return structure, file_map

def smart_split(X, y, groups, strategy, test_size=0.2, manual_target=None):
    """
    groups: è¿™é‡Œçš„ groups ä¼ å…¥çš„æ˜¯æ–‡ä»¶ååˆ—è¡¨ (æ¯ä¸ªæ ·æœ¬å¯¹åº”çš„æ–‡ä»¶å path)
    manual_target: ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®šçš„éªŒè¯é›†å¯¹è±¡ (æ–‡ä»¶å æˆ– æ—¥æœŸæ–‡ä»¶å¤¹å)
    """
    indices = np.arange(len(X))
    train_idx, test_idx = [], []
    
    unique_files = np.unique(groups)
    
    # --- ç­–ç•¥ 1: æ··åˆå¤§ä¹±ç‚– (ä¿æŒä¸å˜) ---
    if strategy == "æ··åˆåˆ‡åˆ† (çœ‹åˆ°æ‰€æœ‰å¤©/äºº)":
        for f in unique_files:
            f_indices = indices[groups == f]
            split_point = int(len(f_indices) * (1 - test_size))
            train_idx.extend(f_indices[:split_point])
            test_idx.extend(f_indices[split_point:])
            
    # --- ç­–ç•¥ 2: ä¸¥æ ¼ç•™ä¸€æ–‡ä»¶ (Leave-One-File-Out) ---
    elif strategy == "ç•™æ–‡ä»¶éªŒè¯ (åŒå¤©/åŒäºº)":
        # === æ–°å¢ï¼šæ‰‹åŠ¨æ¨¡å¼ ===
        if manual_target:
            # groups é‡Œå­˜çš„æ˜¯å…¨è·¯å¾„ï¼Œmanual_target æ˜¯æ–‡ä»¶å (basename)
            # æ‰¾åˆ°æ‰€æœ‰å±äºè¯¥æ–‡ä»¶çš„æ ·æœ¬ç´¢å¼•
            is_test = np.array([os.path.basename(g.split('_seg')[0]) == manual_target for g in groups])
            test_idx = indices[is_test]
            train_idx = indices[~is_test]
        else:
            # === åŸæœ‰ï¼šéšæœºæ¨¡å¼ ===
            gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=42)
            train_i, test_i = next(gss.split(X, y, groups=groups))
            train_idx, test_idx = indices[train_i], indices[test_i]

    # --- ç­–ç•¥ 3: ä¸¥æ ¼ç•™ä¸€æ—¥æœŸ/å¯¹è±¡ (Leave-Group-Out) ---
    elif strategy == "ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯ (æ³›åŒ–èƒ½åŠ›)":
        # æå– Group ID (æ–‡ä»¶å¤¹å)
        real_groups = np.array([os.path.basename(os.path.dirname(f)) for f in groups])
        
        # === æ–°å¢ï¼šæ‰‹åŠ¨æ¨¡å¼ ===
        if manual_target:
            is_test = (real_groups == manual_target)
            test_idx = indices[is_test]
            train_idx = indices[~is_test]
        else:
            # === åŸæœ‰ï¼šéšæœºæ¨¡å¼ ===
            gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=42)
            train_i, test_i = next(gss.split(X, y, groups=real_groups))
            train_idx, test_idx = indices[train_i], indices[test_i]
        
    return np.array(train_idx), np.array(test_idx)

def get_few_shot_split(X, y, n_samples_per_class):
    """
    ä¸ºæ¯ä¸ªç±»åˆ«æå–å›ºå®šæ•°é‡çš„æ ·æœ¬ç”¨äºå¾®è°ƒï¼Œå…¶ä½™ç”¨äºæµ‹è¯•
    """
    train_idx = []
    test_idx = []
    unique_labels = np.unique(y)
    
    for label in unique_labels:
        label_indices = np.where(y == label)[0]
        # éšæœºæ‰“ä¹±
        np.random.shuffle(label_indices)
        # å–å‰ N ä¸ªä½œä¸ºå¾®è°ƒæ ·æœ¬
        train_idx.extend(label_indices[:n_samples_per_class])
        # å‰©ä¸‹çš„ä½œä¸ºæµ‹è¯•
        test_idx.extend(label_indices[n_samples_per_class:])
        
    return np.array(train_idx), np.array(test_idx)

# ================= ç•Œé¢å¸ƒå±€ =================

st.title("ğŸ§  EMG äº¤äº’å¼è®­ç»ƒç³»ç»Ÿ")

# train_gui.py ä¾§è¾¹æ 
st.sidebar.header("ğŸš€ è®­ç»ƒæ¨¡å¼")
train_mode = st.sidebar.radio("é€‰æ‹©æ¨¡å¼", ["ä»é›¶å¼€å§‹è®­ç»ƒ", "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)"])

base_model_path = None
if train_mode == "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)":
    base_model_path = st.sidebar.file_uploader("ä¸Šä¼ åŸºæ¨¡å‹ (.h5)", type=["h5"])
    num_finetune_samples = st.sidebar.slider("æ¯ä¸ªç±»åˆ«ç”¨äºå¾®è°ƒçš„æ ·æœ¬æ•°", 1, 10, 5)

with st.sidebar:
    st.header("1. æ•°æ®é€‰æ‹©")
    DATA_ROOT = "data"
    
    if not os.path.exists(DATA_ROOT):
        st.error(f"æœªæ‰¾åˆ° {DATA_ROOT} æ–‡ä»¶å¤¹")
        st.stop()
        
    structure, file_map = scan_data_folder(DATA_ROOT)
    
# --- çº§è”é€‰æ‹©å™¨ ---

    def render_multiselect_with_all(label, options, key_name, default_first=False):
        """
        label: æ ‡é¢˜
        options: å€™é€‰é¡¹åˆ—è¡¨
        key_name: session_state çš„é”®å
        default_first: æ˜¯å¦é»˜è®¤é€‰ä¸­ç¬¬ä¸€ä¸ª
        """
        # 1. ç¡®ä¿ Session State åˆå§‹åŒ–
        if key_name not in st.session_state:
            if default_first and options:
                st.session_state[key_name] = options[:1]
            else:
                st.session_state[key_name] = []
        
        # 2. æ•°æ®æ¸…æ´— (é˜²æ­¢é€‰é¡¹å˜åŒ–åï¼Œæ®‹ç•™äº†æ— æ•ˆçš„é€‰ä¸­é¡¹)
        current_selection = st.session_state[key_name]
        valid_selection = [x for x in current_selection if x in options]
        if len(valid_selection) != len(current_selection):
            st.session_state[key_name] = valid_selection
            current_selection = valid_selection
            
        # 3. è®¡ç®—å½“å‰æ˜¯å¦â€œå·²å…¨é€‰â€ï¼Œç”¨äºè®¾ç½® Checkbox çš„åˆå§‹çŠ¶æ€
        is_all_selected = (len(current_selection) == len(options)) and (len(options) > 0)
        
        # 4. å®šä¹‰å…¨é€‰å›è°ƒå‡½æ•°
        def toggle_all():
            # è·å– Checkbox çš„æ–°çŠ¶æ€ (æ³¨æ„ï¼šè¿™é‡Œçš„ key æ˜¯æ‹¼æ¥äº† _all çš„)
            if st.session_state[key_name + '_all']:
                st.session_state[key_name] = options # å…¨é€‰
            else:
                st.session_state[key_name] = []      # å…¨ä¸é€‰

        # 5. æ¸²æŸ“ UIï¼šä½¿ç”¨åˆ—å¸ƒå±€ï¼Œè®©â€œæ ‡é¢˜â€å’Œâ€œå…¨é€‰æ¡†â€åœ¨åŒä¸€è¡Œ
        c1, c2 = st.columns([0.7, 0.3], gap="small")
        with c1:
            # æ‰‹åŠ¨æ¸²æŸ“æ ‡é¢˜ï¼ŒåŠ ç²—
            st.markdown(f"**{label}**")
        with c2:
            # æ¸²æŸ“å…¨é€‰æ¡† (æ— æ ‡ç­¾ï¼Œåªæ˜¾ç¤ºæ¡†ï¼ŒèŠ‚çœç©ºé—´)
            st.checkbox(
                "å…¨é€‰", 
                value=is_all_selected, 
                key=key_name + '_all', # ç‹¬ç«‹çš„ key
                on_change=toggle_all,   # ç»‘å®šå›è°ƒ
                help=f"å‹¾é€‰ä»¥é€‰ä¸­æ‰€æœ‰ {label}"
            )
            
        # 6. æ¸²æŸ“å¤šé€‰æ¡† (éšè—è‡ªå¸¦çš„ Label)
        return st.multiselect(
            label=label, # è¿™ä¸ª label ä»…ç”¨äº accessibilityï¼Œä¸å¯è§
            options=options,
            key=key_name,
            label_visibility="collapsed" # éšè—è‡ªå¸¦æ ‡é¢˜ï¼Œå› ä¸ºä¸Šé¢å·²ç»ç”»äº†
        )

    # ================= 1. é€‰æ‹©å¯¹è±¡ (Subject) =================
    all_subjects = sorted(structure.keys())
    
    selected_subjects = render_multiselect_with_all(
        label="é€‰æ‹©æµ‹è¯•è€… (Subjects)",
        options=all_subjects,
        key_name='selected_subjects_key',
        default_first=True
    )
    
    # ================= 2. é€‰æ‹©æ—¥æœŸ (Date) =================
    available_dates = set()
    for s in selected_subjects:
        if s in structure:
            available_dates.update(structure[s].keys())
    sorted_dates = sorted(list(available_dates))
    
    selected_dates = render_multiselect_with_all(
        label="é€‰æ‹©æ—¥æœŸ (Dates)",
        options=sorted_dates,
        key_name='selected_dates_key',
        default_first=True
    )
    
    # ================= 3. é€‰æ‹©åŠ¨ä½œ (Labels) =================
    available_labels = set()
    for s in selected_subjects:
        for d in selected_dates:
            if s in structure and d in structure[s]:
                available_labels.update(structure[s][d])
    sorted_labels = sorted(list(available_labels))
    
    selected_labels = render_multiselect_with_all(
        label="é€‰æ‹©åŠ¨ä½œ ID (Labels)",
        options=sorted_labels,
        key_name='selected_labels_key',
        default_first=True
    )

    
    st.markdown("---")
    
    # ç»Ÿè®¡é€‰ä¸­æ–‡ä»¶
    target_files = []
    for s in selected_subjects:
        for d in selected_dates:
            for l in selected_labels:
                key = (s, d, l)
                if key in file_map:
                    target_files.extend(file_map[key])
    
    st.info(f"å·²é€‰ä¸­ **{len(target_files)}** ä¸ª CSV æ–‡ä»¶")

    st.header("2. å¢å¼ºä¸è®­ç»ƒé…ç½®")
    
    with st.expander("ğŸ› ï¸ æ•°æ®å¢å¼º (Data Augmentation)", expanded=True):
        st.caption("é€šè¿‡å¢åŠ æ•°æ®å¤šæ ·æ€§æ¥é˜²æ­¢è¿‡æ‹Ÿåˆå¹¶æå‡æŠ•ç¥¨æ•ˆæœã€‚")
        
        # 1. åŠ¨æ€æ­¥é•¿ (Level 1)
        # é»˜è®¤ 100msï¼Œè®¾å°ä¸€ç‚¹ï¼ˆæ¯”å¦‚ 50msï¼‰å¯ä»¥æˆå€å¢åŠ çª—å£æ•°é‡
        train_stride_ms = st.slider("åˆ‡ç‰‡æ­¥é•¿ (Stride ms)", 10, 200, 100, 10, 
                                    help="è¶Šå°äº§ç”Ÿçš„çª—å£è¶Šå¤šï¼ŒæŠ•ç¥¨åŸºæ•°è¶Šå¤§ã€‚å»ºè®® 50ms å·¦å³ã€‚")
        
        # 2. ä¿¡å·æ‰°åŠ¨ (Level 2)
        enable_scaling = st.checkbox("å¯ç”¨éšæœºå¹…åº¦ç¼©æ”¾ (Scaling)", value=False)
        enable_noise = st.checkbox("å¯ç”¨é«˜æ–¯å™ªå£° (Gaussian Noise)", value=False)
        
        augment_config = {
            'enable_scaling': enable_scaling,
            'enable_noise': enable_noise
        }
    st.markdown("---")
    st.markdown("##### ğŸ§  æ¨¡å‹æ¶æ„é€‰æ‹©")
    model_type = st.selectbox(
        "é€‰æ‹©æ¨¡å‹æ ¸å¿ƒ",
        ["Lite: Simple CNN (æ¨èå•äºº)", "Pro: Multi-Scale CRNN (æ¨èå¤šäºº/è·¨å¤©)"],
        index=0,
        help="Liteç‰ˆï¼šè®­ç»ƒå¿«ï¼Œé€‚åˆå°æ ·æœ¬ï¼›Proç‰ˆï¼šæŠ—å¹²æ‰°å¼ºï¼Œéœ€è¦è¾ƒå¤šæ•°æ®ã€‚"
    )

    st.markdown("##### ğŸ§ª éªŒè¯ç­–ç•¥é€‰æ‹©")
    split_mode = st.radio(
        "ä½ æƒ³æ€ä¹ˆéªŒè¯æ¨¡å‹ï¼Ÿ",
        (
            "1. æ··åˆåˆ‡åˆ† (æ¨è)", 
            "2. ç•™æ–‡ä»¶éªŒè¯ (è¿›é˜¶)",
            "3. ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯ (é«˜éš¾)"
        ),
        index=0
    )
    
    strategy_map = {
        "1. æ··åˆåˆ‡åˆ† (æ¨è)": "æ··åˆåˆ‡åˆ† (çœ‹åˆ°æ‰€æœ‰å¤©/äºº)",
        "2. ç•™æ–‡ä»¶éªŒè¯ (è¿›é˜¶)": "ç•™æ–‡ä»¶éªŒè¯ (åŒå¤©/åŒäºº)",
        "3. ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯ (é«˜éš¾)": "ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯ (æ³›åŒ–èƒ½åŠ›)"
    }
    selected_strategy = strategy_map[split_mode]

    # === æ–°å¢ï¼šæ ¹æ®ç­–ç•¥æ˜¾ç¤ºâ€œæŒ‡å®šéªŒè¯é›†â€çš„ä¸‹æ‹‰æ¡† ===
    manual_val_target = None
    
    if "ç•™æ–‡ä»¶" in selected_strategy:
        # ä» target_files ä¸­æå–æ‰€æœ‰æ–‡ä»¶å
        if target_files:
            file_options = sorted(list(set([os.path.basename(f) for f in target_files])))
            manual_val_target = st.selectbox(
                "ğŸ¯ æŒ‡å®šå“ªä¸€ä¸ªæ–‡ä»¶åšæµ‹è¯•ï¼Ÿ", 
                file_options,
                help="é€‰ä¸­çš„æ–‡ä»¶å°†å®Œå…¨ä¸å‚ä¸è®­ç»ƒï¼Œåªç”¨æ¥åšæœ€åçš„è€ƒè¯•ã€‚"
            )
            
    elif "ç•™æ—¥æœŸ" in selected_strategy:
        # ä» target_files ä¸­æå–æ‰€æœ‰æ—¥æœŸæ–‡ä»¶å¤¹å
        if target_files:
            group_options = sorted(list(set([os.path.basename(os.path.dirname(f)) for f in target_files])))
            manual_val_target = st.selectbox(
                "ğŸ¯ æŒ‡å®šå“ªä¸€å¤©/å¯¹è±¡åšæµ‹è¯•ï¼Ÿ", 
                group_options,
                help="é€‰ä¸­çš„æ—¥æœŸ/å¯¹è±¡çš„æ‰€æœ‰æ•°æ®éƒ½å°†ä½œä¸ºæµ‹è¯•é›†ï¼Œç”¨äºéªŒè¯æ¨¡å‹çš„è·¨å¤©æ³›åŒ–èƒ½åŠ›ã€‚"
            )


    st.markdown("---") 
    epochs = st.number_input("Epochs", 10, 200, 50)
    batch_size = st.selectbox("Batch Size", [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048], index=2)
    test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.01, 0.5, 0.2)
    
    run_btn = st.button("ğŸš€ å¼€å§‹å¤„ç†å¹¶è®­ç»ƒ", type="primary")
# ================= ä¸»é€»è¾‘åŒºåŸŸ =================

if run_btn and target_files:
    # --- 1. æ•°æ®å¤„ç†é˜¶æ®µ ---
    st.subheader("1. æ•°æ®é¢„å¤„ç†")
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # è°ƒç”¨ data_loader å¤„ç†æ•°æ®
    X, y, groups = data_loader.process_selected_files(
        target_files, 
        progress_callback=lambda p, t: (progress_bar.progress(p), status_text.text(t)),
        stride_ms=train_stride_ms,   # <--- ä¼ å…¥åŠ¨æ€æ­¥é•¿
        augment_config=augment_config # <--- ä¼ å…¥å¢å¼ºé…ç½®
    )
    
    status_text.text("å¤„ç†å®Œæˆï¼")
    progress_bar.progress(100)
    
    if len(X) == 0:
        st.error("ç”Ÿæˆçš„æ ·æœ¬æ•°ä¸º 0ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ…å«æœ‰æ•ˆåŠ¨ä½œæ•°æ®ã€‚")
        st.stop()
        
    st.success(f"æˆåŠŸç”Ÿæˆæ ·æœ¬æ•°æ®: X={X.shape}, y={y.shape}")
    st.write(f"åŒ…å«åŠ¨ä½œç±»åˆ«: {np.unique(y)}")
    
    # --- 2. è®­ç»ƒé˜¶æ®µ ---
    st.subheader("2. æ¨¡å‹è®­ç»ƒ")
    
    # ã€æ–°å¢ä½ç½®ã€‘ï¼šæ ¹æ®æ¨¡å¼é€‰æ‹©åˆ‡åˆ†ç­–ç•¥
    if train_mode == "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)":
        # ä½¿ç”¨åˆšæ‰å®šä¹‰çš„ Few-shot åˆ‡åˆ†å‡½æ•°
        train_idx, test_idx = get_few_shot_split(X, y, num_finetune_samples)
        selected_strategy = f"Few-shot (æ¯ç±» {num_finetune_samples} æ ·æœ¬)"
    else:
        # åŸæœ‰çš„ smart_split é€»è¾‘
        train_idx, test_idx = smart_split(X, y, groups, selected_strategy, test_size)

    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    
    # ... æ ‡ç­¾æ˜ å°„ä»£ç  ...
    unique_labels = np.unique(y)
    
    # 2. è®¡ç®—åˆ†ç±»æ•°é‡ 
    num_classes = len(unique_labels) 
    # 3. æ ‡ç­¾æ˜ å°„ (å°†åŸå§‹æ ‡ç­¾ 1,3,5 æ˜ å°„ä¸º 0,1,2 ç”¨äºè®­ç»ƒ)
    label_map = {original: new for new, original in enumerate(unique_labels)}
    y_train_mapped = np.array([label_map[i] for i in y_train])
    y_test_mapped = np.array([label_map[i] for i in y_test])

    # æ¨¡å‹æ„å»º/åŠ è½½é€»è¾‘
    if train_mode == "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)":
        if base_model_path is not None:
            # åŠ è½½å·²æœ‰çš„æ¨¡å‹æ–‡ä»¶
            with open("temp_model.h5", "wb") as f:
                f.write(base_model_path.getbuffer())
            model = tf.keras.models.load_model("temp_model.h5")
            
            # å†»ç»“å·ç§¯å±‚ï¼Œåªè®­ç»ƒæœ€åä¸¤å±‚å…¨è¿æ¥å±‚
            for layer in model.layers[:-2]:
                layer.trainable = False
            
            # ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡è¿›è¡Œå¾®è°ƒ
            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), 
                          loss='sparse_categorical_crossentropy', 
                          metrics=['accuracy'])
            st.success("åŸºæ¨¡å‹åŠ è½½æˆåŠŸï¼Œå·²å†»ç»“ç‰¹å¾æå–å±‚ã€‚")
        else:
            st.error("è¯·å…ˆä¸Šä¼ åŸºæ¨¡å‹ï¼")
            st.stop()
    else:
        # åŸæœ‰çš„æ¨¡å‹æ„å»ºé€»è¾‘ (build_simple_cnn æˆ– build_advanced_crnn)
        input_shape = (X.shape[1], X.shape[2])
        if "Lite" in model_type:
            model = build_simple_cnn(input_shape=input_shape, num_classes=num_classes)
        else:
            model = build_advanced_crnn(input_shape=input_shape, num_classes=num_classes)
        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    
    st.write("---")
    st.caption("è®­ç»ƒç›‘æ§é¢æ¿")
    train_progress_bar = st.progress(0) # è¿›åº¦æ¡
    train_status_text = st.empty()      # ç”¨äºæ˜¾ç¤ºæ–‡å­—è¯¦æƒ…çš„å ä½ç¬¦
    
    # === æ–°å¢ï¼šå®ä¾‹åŒ–è‡ªå®šä¹‰å›è°ƒ ===
    st_callback = StreamlitKerasCallback(
        total_epochs=epochs, 
        progress_bar=train_progress_bar, 
        status_text=train_status_text
    )

    # è®­ç»ƒå›è°ƒ (æ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹)
    # è¿™é‡Œçš„ st.spinner å¯ä»¥å»æ‰æˆ–è€…ä¿ç•™ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æœ‰è¿›åº¦æ¡äº†ï¼Œä¿ç•™ç€ä¹Ÿä¸å†²çª
    with st.spinner("æ­£åœ¨åˆå§‹åŒ–è®­ç»ƒ..."):
        history = model.fit(
            X_train, y_train_mapped,
            epochs=epochs,
            batch_size=batch_size,
            validation_data=(X_test, y_test_mapped),
            callbacks=[
                EarlyStopping(patience=10, restore_best_weights=True), 
                reduce_lr, 
                st_callback 
            ],
            verbose=0 # ä¿æŒ 0ï¼Œå› ä¸ºæˆ‘ä»¬è‡ªå·±æ¥ç®¡äº†è¾“å‡º
        )
    
    st.success("è®­ç»ƒå®Œæˆï¼")
    
    # --- 3. ç»“æœå¯è§†åŒ– ---
    st.subheader("3. è®­ç»ƒç»“æœ")
    
    col1, col2 = st.columns(2)
    
    # å‡†ç¡®ç‡æ›²çº¿
    with col1:
        fig1, ax1 = plt.subplots()
        ax1.plot(history.history['accuracy'], label='Train Acc')
        ax1.plot(history.history['val_accuracy'], label='Val Acc')
        ax1.set_title("Accuracy Curve")
        ax1.set_xlabel("Epoch")
        ax1.set_ylabel("Accuracy")
        ax1.legend()
        st.pyplot(fig1)
        
    # æŸå¤±æ›²çº¿
    with col2:
        fig2, ax2 = plt.subplots()
        ax2.plot(history.history['loss'], label='Train Loss')
        ax2.plot(history.history['val_loss'], label='Val Loss')
        ax2.set_title("Loss Curve")
        ax2.set_xlabel("Epoch")
        ax2.set_ylabel("Loss")
        ax2.legend()
        st.pyplot(fig2)
    
    # æœ€ç»ˆè¯„ä¼°
    loss, acc = model.evaluate(X_test, y_test_mapped, verbose=0)
    st.metric("æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡ (Test Accuracy)", f"{acc*100:.2f}%")
    
    st.markdown("---")
    st.subheader("ğŸ—³ï¸ å¤šæ•°æŠ•ç¥¨æ¨¡æ‹Ÿ (Majority Voting Simulation)")
    st.caption("ç”±äºæˆ‘ä»¬å‡å°äº† Strideï¼Œæ¯ä¸ªåŠ¨ä½œç‰‡æ®µä¼šè¢«åˆ‡æˆå¤šä¸ªçª—å£ã€‚è¿™é‡Œæ¨¡æ‹ŸçœŸå®æ¨ç†ï¼šç»Ÿè®¡å±äºåŒä¸€ä¸ªåŠ¨ä½œæ–‡ä»¶çš„æ‰€æœ‰çª—å£é¢„æµ‹ç»“æœï¼Œå–ä¼—æ•°ä½œä¸ºæœ€ç»ˆç»“æœã€‚")
    
    # 1. è·å–æµ‹è¯•é›†çš„æ‰€æœ‰é¢„æµ‹ç»“æœ
    y_pred_probs = model.predict(X_test)
    y_pred = np.argmax(y_pred_probs, axis=1)
    
    # 2. è·å–æµ‹è¯•é›†å¯¹åº”çš„åŸå§‹æ–‡ä»¶å½’å± (groups)
    # æ³¨æ„ï¼šsmart_split è¿”å›çš„æ˜¯ç´¢å¼•ï¼Œæˆ‘ä»¬è¦ç”¨ç´¢å¼•å»å– groups
    test_groups = groups[test_idx]
    
    # 3. æŒ‰æ–‡ä»¶åˆ†ç»„ç»Ÿè®¡
    # ç»“æ„: { 'filename_df1.csv': {'true': 1, 'preds': [1, 1, 1, 2, 1]} }
    voting_results = {}
    
    for i, group_name in enumerate(test_groups):
        if group_name not in voting_results:
            voting_results[group_name] = {'true': y_test_mapped[i], 'preds': []}
        voting_results[group_name]['preds'].append(y_pred[i])
        
    # 4. è®¡ç®—æŠ•ç¥¨å‡†ç¡®ç‡
    correct_segments = 0
    total_segments = len(voting_results)
    
    st.write(f"æµ‹è¯•é›†åŒ…å« **{total_segments}** ä¸ªç‹¬ç«‹çš„åŠ¨ä½œç‰‡æ®µ (Segments)ã€‚")
    
    # 5. è®¡ç®—æœ€ç»ˆ Segment-level Accuracy
    for fname, res in voting_results.items():
        counts = np.bincount(res['preds'], minlength=num_classes)
        voted_label = np.argmax(counts)
        if voted_label == res['true']:
            correct_segments += 1
            
    segment_acc = correct_segments / total_segments if total_segments > 0 else 0
    
    # ä½¿ç”¨ä¸¤åˆ—å¹¶æ’æ˜¾ç¤ºæ ¸å¿ƒæŒ‡æ ‡
    col_m1, col_m2 = st.columns(2)
    with col_m1:
        st.metric("çª—å£çº§å‡†ç¡®ç‡ (Window Acc)", f"{acc*100:.2f}%", help="å•ä¸ª250msåˆ‡ç‰‡çš„å‡†ç¡®ç‡")
    with col_m2:
        st.metric("æŠ•ç¥¨åå‡†ç¡®ç‡ (Segment Acc)", f"{segment_acc*100:.2f}%", delta=f"{(segment_acc-acc)*100:.2f}%")

    st.session_state['trained_model'] = model
    st.success("è®­ç»ƒå®Œæˆå¹¶å·²ç¼“å­˜ï¼")

if st.session_state['trained_model'] is not None:
    st.markdown("---")
    st.subheader("ğŸ’¾ æ¨¡å‹ä¿å­˜")
    
    # è·å–ç¼“å­˜çš„æ¨¡å‹
    model_to_save = st.session_state['trained_model']
    
    col_save1, col_save2 = st.columns([0.5, 0.5])
    
    with col_save1:
        save_name = st.text_input("æ¨¡å‹æ–‡ä»¶å", value="my_emg_model.h5")
        
    with col_save2:
        st.write("") # å ä½å¯¹é½
        st.write("") 
        if st.button("ç¡®è®¤ä¿å­˜æ¨¡å‹"):
            try:
                model_to_save.save(save_name)
                st.success(f"âœ… æ¨¡å‹å·²æˆåŠŸä¿å­˜è‡³: {os.path.abspath(save_name)}")
                st.balloons() # æ’’èŠ±ç¡®è®¤
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")

elif run_btn and not target_files:
    st.warning("è¯·å…ˆåœ¨å·¦ä¾§é€‰æ‹©æ•°æ®ï¼")