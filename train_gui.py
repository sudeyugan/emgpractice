import streamlit as st
import os
import tensorflow as tf
import time
from tensorflow.keras.callbacks import Callback

# è·å–æ‰€æœ‰å¯è§çš„ç‰©ç† GPU è®¾å¤‡
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        # è®¾ç½®æ˜¾å­˜æŒ‰éœ€å¢é•¿
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("å·²å¼€å¯æ˜¾å­˜æŒ‰éœ€å¢é•¿æ¨¡å¼")
    except RuntimeError as e:
        print(e)
import glob
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import GroupShuffleSplit
from tensorflow.keras.callbacks import ReduceLROnPlateau

# å¼•å…¥æˆ‘ä»¬è‡ªå®šä¹‰çš„æ¨¡å—
import data_loader
from model import build_simple_cnn, build_advanced_crnn


class StreamlitKerasCallback(Callback):
    """
    ç”¨äºè¿æ¥ Keras è®­ç»ƒè¿‡ç¨‹ä¸ Streamlit è¿›åº¦æ¡çš„è‡ªå®šä¹‰å›è°ƒ
    """
    def __init__(self, total_epochs, progress_bar, status_text):
        super().__init__()
        self.total_epochs = total_epochs
        self.progress_bar = progress_bar
        self.status_text = status_text
        self.start_time = None

    def on_train_begin(self, logs=None):
        self.start_time = time.time()
        self.progress_bar.progress(0)
        self.status_text.text("ğŸš€ å‡†å¤‡å¼€å§‹è®­ç»ƒ...")

    def on_epoch_end(self, epoch, logs=None):
        # epoch æ˜¯ä» 0 å¼€å§‹çš„ä¸‹æ ‡ï¼Œæ‰€ä»¥ +1
        current_epoch = epoch + 1
        
        # 1. æ›´æ–°è¿›åº¦æ¡ (é˜²æ­¢ EarlyStopping å¯¼è‡´æ¯”ä¾‹æº¢å‡ºï¼Œé™åˆ¶åœ¨ 0-1 ä¹‹é—´)
        progress = min(current_epoch / self.total_epochs, 1.0)
        self.progress_bar.progress(progress)
        
        # 2. è®¡ç®—æ—¶é—´
        elapsed_time = time.time() - self.start_time
        avg_time_per_epoch = elapsed_time / current_epoch
        remaining_epochs = self.total_epochs - current_epoch
        eta_seconds = avg_time_per_epoch * remaining_epochs
        
        # æ ¼å¼åŒ–æ—¶é—´å­—ç¬¦ä¸²
        eta_str = time.strftime("%M:%S", time.gmtime(eta_seconds))
        elapsed_str = time.strftime("%M:%S", time.gmtime(elapsed_time))
        
        # 3. è·å–æŒ‡æ ‡ (Loss & Accuracy)
        loss = logs.get('loss', 0)
        acc = logs.get('accuracy', 0)
        val_loss = logs.get('val_loss', 0)
        val_acc = logs.get('val_accuracy', 0)
        
        # 4. æ›´æ–°çŠ¶æ€æ–‡æœ¬
        status_msg = (
            f"Epoch {current_epoch}/{self.total_epochs} | "
            f"â³ å‰©ä½™: {eta_str} (å·²ç”¨: {elapsed_str}) | "
            f"Loss: {loss:.4f} Acc: {acc:.1%} | "
            f"Val Loss: {val_loss:.4f} Val Acc: {val_acc:.1%}"
        )
        self.status_text.text(status_msg)

    def on_train_end(self, logs=None):
        # è®­ç»ƒç»“æŸï¼ˆåŒ…æ‹¬æ—©åœï¼‰ï¼Œå°†è¿›åº¦æ¡æ‹‰æ»¡å¹¶æç¤º
        self.progress_bar.progress(100)
        self.status_text.text("âœ… è®­ç»ƒå·²å®Œæˆï¼")

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',    # ç›‘æ§éªŒè¯é›†çš„æŸå¤±å€¼
    factor=0.5,             # å­¦ä¹ ç‡è°ƒæ•´å€æ•°ï¼šå½“è§¦å‘æ—¶ï¼Œæ–°å­¦ä¹ ç‡ = æ—§å­¦ä¹ ç‡ * 0.5
    patience=5,             # è€å¿ƒå€¼ï¼šå¦‚æœè¿ç»­ 5 ä¸ª epoch éªŒè¯é›†æŸå¤±éƒ½æ²¡æœ‰æ”¹å–„ï¼Œåˆ™è§¦å‘
    min_lr=1e-6,            # å­¦ä¹ ç‡ä¸‹é™ï¼šé˜²æ­¢å­¦ä¹ ç‡è¢«å‡åˆ°è¿‡å°
    verbose=1               # è§¦å‘æ—¶åœ¨ç»ˆç«¯æ‰“å°æ¶ˆæ¯
)

st.set_page_config(layout="wide", page_title="EMG è®­ç»ƒå·¥ä½œç«™")

# ================= 1. æ–‡ä»¶æ‰«æé€»è¾‘ =================
@st.cache_data
def scan_data_folder(root_dir):
    """æ‰«ææ–‡ä»¶å¤¹ï¼Œæ„å»º Subject -> Date -> Labels ç»“æ„"""
    structure = {}
    file_map = {} # å­˜å‚¨ label -> file_path listï¼Œç”¨äºå¿«é€Ÿæ£€ç´¢
    
    # æŸ¥æ‰¾æ‰€æœ‰ RAW_EMG æ–‡ä»¶
    pattern = os.path.join(root_dir, "*", "*", "RAW_EMG*.csv")
    files = glob.glob(pattern)
    
    for f in files:
        subject, date, label, fname = data_loader.parse_filename_info(f)
        if label is None: continue
        
        if subject not in structure: structure[subject] = {}
        if date not in structure[subject]: structure[subject][date] = set()
        
        structure[subject][date].add(label)
        
        # æ„å»ºç´¢å¼•é”®
        key = (subject, date, label)
        if key not in file_map: file_map[key] = []
        file_map[key].append(f)
        
    return structure, file_map

def smart_split(X, y, groups, strategy, test_size=0.2, manual_target=None):
    """
    groups: è¿™é‡Œçš„ groups ä¼ å…¥çš„æ˜¯æ–‡ä»¶ååˆ—è¡¨ (æ¯ä¸ªæ ·æœ¬å¯¹åº”çš„æ–‡ä»¶å path)
    manual_target: ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®šçš„éªŒè¯é›†å¯¹è±¡ (æ–‡ä»¶å æˆ– æ—¥æœŸæ–‡ä»¶å¤¹å)
    """
    indices = np.arange(len(X))
    train_idx, test_idx = [], []
    
    unique_files = np.unique(groups)
    
    # --- ç­–ç•¥ 1: æ··åˆå¤§ä¹±ç‚– (ä¿æŒä¸å˜) ---
    if strategy == "æ··åˆåˆ‡åˆ† (çœ‹åˆ°æ‰€æœ‰å¤©/äºº)":
        for f in unique_files:
            f_indices = indices[groups == f]
            split_point = int(len(f_indices) * (1 - test_size))
            train_idx.extend(f_indices[:split_point])
            test_idx.extend(f_indices[split_point:])
            
    # --- ç­–ç•¥ 2: ä¸¥æ ¼ç•™ä¸€æ–‡ä»¶ (Leave-One-File-Out) ---
    elif strategy == "ç•™æ–‡ä»¶éªŒè¯ (åŒå¤©/åŒäºº)":
        # === æ–°å¢ï¼šæ‰‹åŠ¨æ¨¡å¼ ===
        if manual_target:
            # groups é‡Œå­˜çš„æ˜¯å…¨è·¯å¾„ï¼Œmanual_target æ˜¯æ–‡ä»¶å (basename)
            # æ‰¾åˆ°æ‰€æœ‰å±äºè¯¥æ–‡ä»¶çš„æ ·æœ¬ç´¢å¼•
            is_test = np.array([os.path.basename(f) == manual_target for f in groups])
            test_idx = indices[is_test]
            train_idx = indices[~is_test]
        else:
            # === åŸæœ‰ï¼šéšæœºæ¨¡å¼ ===
            gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=42)
            train_i, test_i = next(gss.split(X, y, groups=groups))
            train_idx, test_idx = indices[train_i], indices[test_i]

    # --- ç­–ç•¥ 3: ä¸¥æ ¼ç•™ä¸€æ—¥æœŸ/å¯¹è±¡ (Leave-Group-Out) ---
    elif strategy == "ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯ (æ³›åŒ–èƒ½åŠ›)":
        # æå– Group ID (æ–‡ä»¶å¤¹å)
        real_groups = np.array([os.path.basename(os.path.dirname(f)) for f in groups])
        
        # === æ–°å¢ï¼šæ‰‹åŠ¨æ¨¡å¼ ===
        if manual_target:
            is_test = (real_groups == manual_target)
            test_idx = indices[is_test]
            train_idx = indices[~is_test]
        else:
            # === åŸæœ‰ï¼šéšæœºæ¨¡å¼ ===
            gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=42)
            train_i, test_i = next(gss.split(X, y, groups=real_groups))
            train_idx, test_idx = indices[train_i], indices[test_i]
        
    return np.array(train_idx), np.array(test_idx)

# ================= ç•Œé¢å¸ƒå±€ =================

st.title("ğŸ§  EMG äº¤äº’å¼è®­ç»ƒç³»ç»Ÿ")

with st.sidebar:
    st.header("1. æ•°æ®é€‰æ‹©")
    DATA_ROOT = "data"
    
    if not os.path.exists(DATA_ROOT):
        st.error(f"æœªæ‰¾åˆ° {DATA_ROOT} æ–‡ä»¶å¤¹")
        st.stop()
        
    structure, file_map = scan_data_folder(DATA_ROOT)
    
# --- çº§è”é€‰æ‹©å™¨ ---
    # 1. é€‰æ‹©å¯¹è±¡ (Subject)
    # é€»è¾‘ï¼šé»˜è®¤é€‰ä¸­ç¬¬ä¸€ä¸ª
    all_subjects = sorted(structure.keys())
    selected_subjects = st.multiselect(
        "é€‰æ‹©æµ‹è¯•è€… (Subjects)", 
        all_subjects, 
        default=all_subjects[:1] # ä¿æŒä¸å˜ï¼Œå·²ç»æ˜¯é»˜è®¤é€‰ç¬¬ä¸€ä¸ª
    )
    
    # 2. é€‰æ‹©æ—¥æœŸ (Date) - åŸºäºé€‰ä¸­çš„å¯¹è±¡
    available_dates = set()
    for s in selected_subjects:
        if s in structure:
            available_dates.update(structure[s].keys())
    
    # æ’åºæ—¥æœŸåˆ—è¡¨
    sorted_dates = sorted(list(available_dates))
    
    # ä¿®æ”¹ç‚¹ï¼šdefault=sorted_dates[:1] è¡¨ç¤ºé»˜è®¤åªé€‰ç¬¬ä¸€ä¸ª
    selected_dates = st.multiselect(
        "é€‰æ‹©æ—¥æœŸ (Dates)", 
        sorted_dates, 
        default=sorted_dates[:1] 
    )
    
    # 3. é€‰æ‹©åŠ¨ä½œ (Labels) - åŸºäºé€‰ä¸­çš„å¯¹è±¡å’Œæ—¥æœŸ
    available_labels = set()
    for s in selected_subjects:
        for d in selected_dates:
            if s in structure and d in structure[s]:
                available_labels.update(structure[s][d])
    
    # æ’åºæ ‡ç­¾åˆ—è¡¨
    sorted_labels = sorted(list(available_labels))
    
    # ä¿®æ”¹ç‚¹ï¼šdefault=sorted_labels[:1] è¡¨ç¤ºé»˜è®¤åªé€‰ç¬¬ä¸€ä¸ª
    selected_labels = st.multiselect(
        "é€‰æ‹©åŠ¨ä½œ ID (Labels)", 
        sorted_labels, 
        default=sorted_labels[:1]
    )

    st.markdown("---")
    
    # ç»Ÿè®¡é€‰ä¸­æ–‡ä»¶
    target_files = []
    for s in selected_subjects:
        for d in selected_dates:
            for l in selected_labels:
                key = (s, d, l)
                if key in file_map:
                    target_files.extend(file_map[key])
    
    st.info(f"å·²é€‰ä¸­ **{len(target_files)}** ä¸ª CSV æ–‡ä»¶")

    st.header("2. å¢å¼ºä¸è®­ç»ƒé…ç½®")
    
    with st.expander("ğŸ› ï¸ æ•°æ®å¢å¼º (Data Augmentation)", expanded=True):
        st.caption("é€šè¿‡å¢åŠ æ•°æ®å¤šæ ·æ€§æ¥é˜²æ­¢è¿‡æ‹Ÿåˆå¹¶æå‡æŠ•ç¥¨æ•ˆæœã€‚")
        
        # 1. åŠ¨æ€æ­¥é•¿ (Level 1)
        # é»˜è®¤ 100msï¼Œè®¾å°ä¸€ç‚¹ï¼ˆæ¯”å¦‚ 50msï¼‰å¯ä»¥æˆå€å¢åŠ çª—å£æ•°é‡
        train_stride_ms = st.slider("åˆ‡ç‰‡æ­¥é•¿ (Stride ms)", 10, 200, 100, 10, 
                                    help="è¶Šå°äº§ç”Ÿçš„çª—å£è¶Šå¤šï¼ŒæŠ•ç¥¨åŸºæ•°è¶Šå¤§ã€‚å»ºè®® 50ms å·¦å³ã€‚")
        
        # 2. ä¿¡å·æ‰°åŠ¨ (Level 2)
        enable_scaling = st.checkbox("å¯ç”¨éšæœºå¹…åº¦ç¼©æ”¾ (Scaling)", value=False)
        enable_noise = st.checkbox("å¯ç”¨é«˜æ–¯å™ªå£° (Gaussian Noise)", value=False)
        
        augment_config = {
            'enable_scaling': enable_scaling,
            'enable_noise': enable_noise
        }
    st.markdown("---")
    st.markdown("##### ğŸ§  æ¨¡å‹æ¶æ„é€‰æ‹©")
    model_type = st.selectbox(
        "é€‰æ‹©æ¨¡å‹æ ¸å¿ƒ",
        ["Lite: Simple CNN (æ¨èå•äºº)", "Pro: Multi-Scale CRNN (æ¨èå¤šäºº/è·¨å¤©)"],
        index=0,
        help="Liteç‰ˆï¼šè®­ç»ƒå¿«ï¼Œé€‚åˆå°æ ·æœ¬ï¼›Proç‰ˆï¼šæŠ—å¹²æ‰°å¼ºï¼Œéœ€è¦è¾ƒå¤šæ•°æ®ã€‚"
    )

    st.markdown("##### ğŸ§ª éªŒè¯ç­–ç•¥é€‰æ‹©")
    split_mode = st.radio(
        "ä½ æƒ³æ€ä¹ˆéªŒè¯æ¨¡å‹ï¼Ÿ",
        (
            "1. æ··åˆåˆ‡åˆ† (æ¨è)", 
            "2. ç•™æ–‡ä»¶éªŒè¯ (è¿›é˜¶)",
            "3. ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯ (é«˜éš¾)"
        ),
        index=0
    )
    
    strategy_map = {
        "1. æ··åˆåˆ‡åˆ† (æ¨è)": "æ··åˆåˆ‡åˆ† (çœ‹åˆ°æ‰€æœ‰å¤©/äºº)",
        "2. ç•™æ–‡ä»¶éªŒè¯ (è¿›é˜¶)": "ç•™æ–‡ä»¶éªŒè¯ (åŒå¤©/åŒäºº)",
        "3. ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯ (é«˜éš¾)": "ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯ (æ³›åŒ–èƒ½åŠ›)"
    }
    selected_strategy = strategy_map[split_mode]

    # === æ–°å¢ï¼šæ ¹æ®ç­–ç•¥æ˜¾ç¤ºâ€œæŒ‡å®šéªŒè¯é›†â€çš„ä¸‹æ‹‰æ¡† ===
    manual_val_target = None
    
    if "ç•™æ–‡ä»¶" in selected_strategy:
        # ä» target_files ä¸­æå–æ‰€æœ‰æ–‡ä»¶å
        if target_files:
            file_options = sorted(list(set([os.path.basename(f) for f in target_files])))
            manual_val_target = st.selectbox(
                "ğŸ¯ æŒ‡å®šå“ªä¸€ä¸ªæ–‡ä»¶åšæµ‹è¯•ï¼Ÿ", 
                file_options,
                help="é€‰ä¸­çš„æ–‡ä»¶å°†å®Œå…¨ä¸å‚ä¸è®­ç»ƒï¼Œåªç”¨æ¥åšæœ€åçš„è€ƒè¯•ã€‚"
            )
            
    elif "ç•™æ—¥æœŸ" in selected_strategy:
        # ä» target_files ä¸­æå–æ‰€æœ‰æ—¥æœŸæ–‡ä»¶å¤¹å
        if target_files:
            group_options = sorted(list(set([os.path.basename(os.path.dirname(f)) for f in target_files])))
            manual_val_target = st.selectbox(
                "ğŸ¯ æŒ‡å®šå“ªä¸€å¤©/å¯¹è±¡åšæµ‹è¯•ï¼Ÿ", 
                group_options,
                help="é€‰ä¸­çš„æ—¥æœŸ/å¯¹è±¡çš„æ‰€æœ‰æ•°æ®éƒ½å°†ä½œä¸ºæµ‹è¯•é›†ï¼Œç”¨äºéªŒè¯æ¨¡å‹çš„è·¨å¤©æ³›åŒ–èƒ½åŠ›ã€‚"
            )


    st.markdown("---") 
    epochs = st.number_input("Epochs", 10, 200, 50)
    batch_size = st.selectbox("Batch Size", [16, 32, 64], index=1)
    test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.5, 0.2)
    
    run_btn = st.button("ğŸš€ å¼€å§‹å¤„ç†å¹¶è®­ç»ƒ", type="primary")
# ================= ä¸»é€»è¾‘åŒºåŸŸ =================

if run_btn and target_files:
    # --- 1. æ•°æ®å¤„ç†é˜¶æ®µ ---
    st.subheader("1. æ•°æ®é¢„å¤„ç†")
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # è°ƒç”¨ data_loader å¤„ç†æ•°æ®
    X, y, groups = data_loader.process_selected_files(
        target_files, 
        progress_callback=lambda p, t: (progress_bar.progress(p), status_text.text(t)),
        stride_ms=train_stride_ms,   # <--- ä¼ å…¥åŠ¨æ€æ­¥é•¿
        augment_config=augment_config # <--- ä¼ å…¥å¢å¼ºé…ç½®
    )
    
    status_text.text("å¤„ç†å®Œæˆï¼")
    progress_bar.progress(100)
    
    if len(X) == 0:
        st.error("ç”Ÿæˆçš„æ ·æœ¬æ•°ä¸º 0ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ…å«æœ‰æ•ˆåŠ¨ä½œæ•°æ®ã€‚")
        st.stop()
        
    st.success(f"æˆåŠŸç”Ÿæˆæ ·æœ¬æ•°æ®: X={X.shape}, y={y.shape}")
    st.write(f"åŒ…å«åŠ¨ä½œç±»åˆ«: {np.unique(y)}")
    
    # --- 2. è®­ç»ƒé˜¶æ®µ ---
    st.subheader("2. æ¨¡å‹è®­ç»ƒ")
    
    train_idx, test_idx = smart_split(X, y, groups, selected_strategy, test_size)
    
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    st.info(f"æ•°æ®é›†åˆ’åˆ†ç»“æœ ({selected_strategy}):\n"
            f"- è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬\n"
            f"- æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")

    # é‡æ–°æ˜ å°„æ ‡ç­¾ (ä¿æŒä¸å˜)
    unique_labels = np.unique(y)
    label_map = {original: new for new, original in enumerate(unique_labels)}
    y_train_mapped = np.array([label_map[i] for i in y_train])
    y_test_mapped = np.array([label_map[i] for i in y_test])
    
    # æ£€æŸ¥æµ‹è¯•é›†æ˜¯å¦åŒ…å«è®­ç»ƒé›†æ²¡æœ‰çš„æ ‡ç­¾ (é˜²æ­¢æŠ¥é”™)
    if len(np.unique(y_test)) < len(unique_labels) and "è·¨æ–‡ä»¶" in selected_strategy:
        st.warning("âš ï¸ æ³¨æ„ï¼šæµ‹è¯•é›†ä¸­æŸäº›åŠ¨ä½œç±»åˆ«å¯èƒ½ç¼ºå¤±ï¼Œè¿™é€šå¸¸æ˜¯å› ä¸ºé€‰ä¸­çš„æ–‡ä»¶å¤ªå°‘ï¼Œå¯¼è‡´æŒ‰æ–‡ä»¶åˆ‡åˆ†æ—¶æŠŠæŸä¸ªåŠ¨ä½œçš„æ‰€æœ‰æ–‡ä»¶éƒ½åˆ†åˆ°äº†è®­ç»ƒé›†ã€‚")
    
    num_classes = len(unique_labels)
    
    st.subheader(f"æ­£åœ¨æ„å»ºæ¨¡å‹: {model_type.split(':')[0]}")
    
    input_shape = (X.shape[1], X.shape[2])
    
    # === æ ¹æ®é€‰æ‹©è°ƒç”¨ä¸åŒçš„æ¨¡å‹æ„å»ºå‡½æ•° ===
    if "Lite" in model_type:
        model = build_simple_cnn(input_shape=input_shape, num_classes=num_classes)
        st.caption("å·²åŠ è½½ Simple CNNï¼šç»“æ„è½»é‡ï¼Œä¸“æ³¨å±€éƒ¨ç‰¹å¾ã€‚")
    else:
        model = build_advanced_crnn(input_shape=input_shape, num_classes=num_classes)
        st.caption("å·²åŠ è½½ Multi-Scale CRNNï¼šå¤šå°ºåº¦è§†é‡ + æ—¶åºè®°å¿†ã€‚")
        
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    
    st.write("---")
    st.caption("è®­ç»ƒç›‘æ§é¢æ¿")
    train_progress_bar = st.progress(0) # è¿›åº¦æ¡
    train_status_text = st.empty()      # ç”¨äºæ˜¾ç¤ºæ–‡å­—è¯¦æƒ…çš„å ä½ç¬¦
    
    # === æ–°å¢ï¼šå®ä¾‹åŒ–è‡ªå®šä¹‰å›è°ƒ ===
    st_callback = StreamlitKerasCallback(
        total_epochs=epochs, 
        progress_bar=train_progress_bar, 
        status_text=train_status_text
    )

    # è®­ç»ƒå›è°ƒ (æ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹)
    # è¿™é‡Œçš„ st.spinner å¯ä»¥å»æ‰æˆ–è€…ä¿ç•™ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æœ‰è¿›åº¦æ¡äº†ï¼Œä¿ç•™ç€ä¹Ÿä¸å†²çª
    with st.spinner("æ­£åœ¨åˆå§‹åŒ–è®­ç»ƒ..."):
        history = model.fit(
            X_train, y_train_mapped,
            epochs=epochs,
            batch_size=batch_size,
            validation_data=(X_test, y_test_mapped),
            callbacks=[
                EarlyStopping(patience=10, restore_best_weights=True), 
                reduce_lr, 
                st_callback  # <--- é‡ç‚¹ï¼šæŠŠæˆ‘ä»¬åˆšæ‰å†™çš„ callback åŠ è¿›å»
            ],
            verbose=0 # ä¿æŒ 0ï¼Œå› ä¸ºæˆ‘ä»¬è‡ªå·±æ¥ç®¡äº†è¾“å‡º
        )
    
    st.success("è®­ç»ƒå®Œæˆï¼")
    
    # --- 3. ç»“æœå¯è§†åŒ– ---
    st.subheader("3. è®­ç»ƒç»“æœ")
    
    col1, col2 = st.columns(2)
    
    # å‡†ç¡®ç‡æ›²çº¿
    with col1:
        fig1, ax1 = plt.subplots()
        ax1.plot(history.history['accuracy'], label='Train Acc')
        ax1.plot(history.history['val_accuracy'], label='Val Acc')
        ax1.set_title("Accuracy Curve")
        ax1.set_xlabel("Epoch")
        ax1.set_ylabel("Accuracy")
        ax1.legend()
        st.pyplot(fig1)
        
    # æŸå¤±æ›²çº¿
    with col2:
        fig2, ax2 = plt.subplots()
        ax2.plot(history.history['loss'], label='Train Loss')
        ax2.plot(history.history['val_loss'], label='Val Loss')
        ax2.set_title("Loss Curve")
        ax2.set_xlabel("Epoch")
        ax2.set_ylabel("Loss")
        ax2.legend()
        st.pyplot(fig2)
    
    # æœ€ç»ˆè¯„ä¼°
    loss, acc = model.evaluate(X_test, y_test_mapped, verbose=0)
    st.metric("æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡ (Test Accuracy)", f"{acc*100:.2f}%")
    
    st.markdown("---")
    st.subheader("ğŸ—³ï¸ å¤šæ•°æŠ•ç¥¨æ¨¡æ‹Ÿ (Majority Voting Simulation)")
    st.caption("ç”±äºæˆ‘ä»¬å‡å°äº† Strideï¼Œæ¯ä¸ªåŠ¨ä½œç‰‡æ®µä¼šè¢«åˆ‡æˆå¤šä¸ªçª—å£ã€‚è¿™é‡Œæ¨¡æ‹ŸçœŸå®æ¨ç†ï¼šç»Ÿè®¡å±äºåŒä¸€ä¸ªåŠ¨ä½œæ–‡ä»¶çš„æ‰€æœ‰çª—å£é¢„æµ‹ç»“æœï¼Œå–ä¼—æ•°ä½œä¸ºæœ€ç»ˆç»“æœã€‚")
    
    # 1. è·å–æµ‹è¯•é›†çš„æ‰€æœ‰é¢„æµ‹ç»“æœ
    y_pred_probs = model.predict(X_test)
    y_pred = np.argmax(y_pred_probs, axis=1)
    
    # 2. è·å–æµ‹è¯•é›†å¯¹åº”çš„åŸå§‹æ–‡ä»¶å½’å± (groups)
    # æ³¨æ„ï¼šsmart_split è¿”å›çš„æ˜¯ç´¢å¼•ï¼Œæˆ‘ä»¬è¦ç”¨ç´¢å¼•å»å– groups
    test_groups = groups[test_idx]
    
    # 3. æŒ‰æ–‡ä»¶åˆ†ç»„ç»Ÿè®¡
    # ç»“æ„: { 'filename_df1.csv': {'true': 1, 'preds': [1, 1, 1, 2, 1]} }
    voting_results = {}
    
    for i, group_name in enumerate(test_groups):
        if group_name not in voting_results:
            voting_results[group_name] = {'true': y_test_mapped[i], 'preds': []}
        voting_results[group_name]['preds'].append(y_pred[i])
        
    # 4. è®¡ç®—æŠ•ç¥¨å‡†ç¡®ç‡
    correct_segments = 0
    total_segments = len(voting_results)
    
    st.write(f"æµ‹è¯•é›†åŒ…å« **{total_segments}** ä¸ªç‹¬ç«‹çš„åŠ¨ä½œç‰‡æ®µ (Segments)ã€‚")
    
    # 5. è®¡ç®—æœ€ç»ˆ Segment-level Accuracy
    for fname, res in voting_results.items():
        counts = np.bincount(res['preds'], minlength=num_classes)
        voted_label = np.argmax(counts)
        if voted_label == res['true']:
            correct_segments += 1
            
    segment_acc = correct_segments / total_segments if total_segments > 0 else 0
    
    # ä½¿ç”¨ä¸¤åˆ—å¹¶æ’æ˜¾ç¤ºæ ¸å¿ƒæŒ‡æ ‡
    col_m1, col_m2 = st.columns(2)
    with col_m1:
        st.metric("çª—å£çº§å‡†ç¡®ç‡ (Window Acc)", f"{acc*100:.2f}%", help="å•ä¸ª250msåˆ‡ç‰‡çš„å‡†ç¡®ç‡")
    with col_m2:
        st.metric("æŠ•ç¥¨åå‡†ç¡®ç‡ (Segment Acc)", f"{segment_acc*100:.2f}%", delta=f"{(segment_acc-acc)*100:.2f}%")
    # ä¿å­˜æ¨¡å‹é€‰é¡¹
    if st.button("ğŸ’¾ ä¿å­˜å½“å‰æ¨¡å‹"):
        model.save("custom_selection_model.h5")
        st.toast("æ¨¡å‹å·²ä¿å­˜ä¸º custom_selection_model.h5")

elif run_btn and not target_files:
    st.warning("è¯·å…ˆåœ¨å·¦ä¾§é€‰æ‹©æ•°æ®ï¼")