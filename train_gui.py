import streamlit as st
import os
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# --- æ¨¡å—å¯¼å…¥ ---
import data_loader
import train_utils  # æ–°å¯¼å…¥
import ui_helper    # æ–°å¯¼å…¥
from model import build_simple_cnn, build_advanced_crnn

# ================= 0. å…¨å±€è®¾ç½® =================
# è·å– GPU è®¾ç½® (è¿™æ®µä»£ç æœ€å¥½æ”¾åœ¨æœ€å‰é¢)
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

st.set_page_config(layout="wide", page_title="EMG è®­ç»ƒå·¥ä½œç«™")

# åˆå§‹åŒ– Session State
if 'trained_model' not in st.session_state:
    st.session_state['trained_model'] = None

# ================= 1. ä¾§è¾¹æ é…ç½® =================
st.sidebar.header("ğŸš€ è®­ç»ƒæ¨¡å¼")
train_mode = st.sidebar.radio("é€‰æ‹©æ¨¡å¼", ["ä»é›¶å¼€å§‹è®­ç»ƒ", "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)"])

base_model_path = None
if train_mode == "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)":
    base_model_path = st.sidebar.file_uploader("ä¸Šä¼ åŸºæ¨¡å‹ (.h5)", type=["h5"])
    num_finetune_samples = st.sidebar.slider("æ¯ä¸ªç±»åˆ«ç”¨äºå¾®è°ƒçš„æ ·æœ¬æ•°", 1, 10, 5)

with st.sidebar:
    st.header("1. æ•°æ®é€‰æ‹©")
    DATA_ROOT = "data"
    
    if not os.path.exists(DATA_ROOT):
        st.error(f"æœªæ‰¾åˆ° {DATA_ROOT} æ–‡ä»¶å¤¹")
        st.stop()
        
    # è°ƒç”¨ ui_helper æ‰«ææ–‡ä»¶
    structure, file_map = ui_helper.scan_data_folder(DATA_ROOT)
    
    # --- çº§è”é€‰æ‹©å™¨ (è°ƒç”¨ ui_helper) ---
    all_subjects = sorted(structure.keys())
    selected_subjects = ui_helper.render_multiselect_with_all(
        "é€‰æ‹©æµ‹è¯•è€… (Subjects)", all_subjects, 'selected_subjects_key', default_first=True
    )
    
    available_dates = set()
    for s in selected_subjects:
        if s in structure: available_dates.update(structure[s].keys())
    selected_dates = ui_helper.render_multiselect_with_all(
        "é€‰æ‹©æ—¥æœŸ (Dates)", sorted(list(available_dates)), 'selected_dates_key', default_first=True
    )
    
    available_labels = set()
    for s in selected_subjects:
        for d in selected_dates:
            if s in structure and d in structure[s]: available_labels.update(structure[s][d])
    selected_labels = ui_helper.render_multiselect_with_all(
        "é€‰æ‹©åŠ¨ä½œ ID (Labels)", sorted(list(available_labels)), 'selected_labels_key', default_first=True
    )

    st.markdown("---")
    
    # ç»Ÿè®¡é€‰ä¸­æ–‡ä»¶
    target_files = []
    for s in selected_subjects:
        for d in selected_dates:
            for l in selected_labels:
                key = (s, d, l)
                if key in file_map: target_files.extend(file_map[key])
    
    st.info(f"å·²é€‰ä¸­ **{len(target_files)}** ä¸ª CSV æ–‡ä»¶")

    st.header("2. å¢å¼ºä¸è®­ç»ƒé…ç½®")
    
    with st.expander("ğŸ› ï¸ æ•°æ®å¢å¼º", expanded=True):
        train_stride_ms = st.slider("åˆ‡ç‰‡æ­¥é•¿ (Stride ms)", 10, 200, 100, 10, help="å»ºè®® 50ms å·¦å³ã€‚")
        enable_scaling = st.checkbox("å¯ç”¨éšæœºå¹…åº¦ç¼©æ”¾", value=False)
        enable_noise = st.checkbox("å¯ç”¨é«˜æ–¯å™ªå£°", value=False)
        augment_config = {'enable_scaling': enable_scaling, 'enable_noise': enable_noise}
        
    st.markdown("---")
    model_type = st.selectbox("é€‰æ‹©æ¨¡å‹æ ¸å¿ƒ", ["Lite: Simple CNN", "Pro: Multi-Scale CRNN"])

    split_mode = st.radio("éªŒè¯ç­–ç•¥", ("1. æ··åˆåˆ‡åˆ†", "2. ç•™æ–‡ä»¶éªŒè¯", "3. ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯"))
    
    strategy_map = {
        "1. æ··åˆåˆ‡åˆ†": "æ··åˆåˆ‡åˆ† (çœ‹åˆ°æ‰€æœ‰å¤©/äºº)",
        "2. ç•™æ–‡ä»¶éªŒè¯": "ç•™æ–‡ä»¶éªŒè¯ (åŒå¤©/åŒäºº)",
        "3. ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯": "ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯ (æ³›åŒ–èƒ½åŠ›)"
    }
    selected_strategy = strategy_map[split_mode]

    manual_val_target = None
    if "ç•™æ–‡ä»¶" in selected_strategy and target_files:
        file_options = sorted(list(set([os.path.basename(f) for f in target_files])))
        manual_val_target = st.selectbox("ğŸ¯ æŒ‡å®šæµ‹è¯•æ–‡ä»¶", file_options)
    elif "ç•™æ—¥æœŸ" in selected_strategy and target_files:
        group_options = sorted(list(set([os.path.basename(os.path.dirname(f)) for f in target_files])))
        manual_val_target = st.selectbox("ğŸ¯ æŒ‡å®šæµ‹è¯•å¯¹è±¡/æ—¥æœŸ", group_options)

    st.markdown("---") 
    epochs = st.number_input("Epochs", 10, 200, 50)
    batch_size = st.selectbox("Batch Size", [16, 32, 64, 128], index=1)
    test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.01, 0.5, 0.2)
    
    run_btn = st.button("ğŸš€ å¼€å§‹å¤„ç†å¹¶è®­ç»ƒ", type="primary")

# ================= 2. ä¸»é€»è¾‘åŒºåŸŸ =================
st.title("ğŸ§  EMG äº¤äº’å¼è®­ç»ƒç³»ç»Ÿ")

if run_btn and target_files:
    # --- A. æ•°æ®å¤„ç† ---
    st.subheader("1. æ•°æ®é¢„å¤„ç†")
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    X, y, groups = data_loader.process_selected_files(
        target_files, 
        progress_callback=lambda p, t: (progress_bar.progress(p), status_text.text(t)),
        stride_ms=train_stride_ms,
        augment_config=augment_config
    )
    
    status_text.text("å¤„ç†å®Œæˆï¼")
    progress_bar.progress(100)
    
    if len(X) == 0:
        st.error("æ ·æœ¬æ•°ä¸º 0ï¼Œè¯·æ£€æŸ¥æ•°æ®ã€‚")
        st.stop()
        
    st.success(f"X={X.shape}, y={y.shape} | ç±»åˆ«: {np.unique(y)}")
    
    # --- B. æ¨¡å‹è®­ç»ƒå‡†å¤‡ ---
    st.subheader("2. æ¨¡å‹è®­ç»ƒ")
    
    # åˆ’åˆ†æ•°æ®é›† (è°ƒç”¨ train_utils)
    if train_mode == "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)":
        train_idx, test_idx = train_utils.get_few_shot_split(X, y, num_finetune_samples)
    else:
        train_idx, test_idx = train_utils.smart_split(
            X, y, groups, selected_strategy, test_size, manual_target=manual_val_target
        )

    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    
    # æ ‡ç­¾æ˜ å°„
    unique_labels = np.unique(y)
    num_classes = len(unique_labels) 
    label_map = {original: new for new, original in enumerate(unique_labels)}
    y_train_mapped = np.array([label_map[i] for i in y_train])
    y_test_mapped = np.array([label_map[i] for i in y_test])

    # æ„å»ºæ¨¡å‹
    if train_mode == "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)":
        if base_model_path:
            with open("temp_model.h5", "wb") as f: f.write(base_model_path.getbuffer())
            model = tf.keras.models.load_model("temp_model.h5")
            for layer in model.layers[:-2]: layer.trainable = False
            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), 
                          loss='sparse_categorical_crossentropy', metrics=['accuracy'])
            st.success("åŸºæ¨¡å‹åŠ è½½æˆåŠŸ (å†»ç»“å±‚).")
        else:
            st.error("è¯·ä¸Šä¼ åŸºæ¨¡å‹")
            st.stop()
    else:
        input_shape = (X.shape[1], X.shape[2])
        if "Lite" in model_type:
            model = build_simple_cnn(input_shape, num_classes)
        else:
            model = build_advanced_crnn(input_shape, num_classes)
        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    
    # --- C. å¼€å§‹è®­ç»ƒ ---
    st.caption("è®­ç»ƒç›‘æ§")
    train_progress = st.progress(0)
    train_status = st.empty()
    
    # å®ä¾‹åŒ–å›è°ƒ (è°ƒç”¨ train_utils)
    st_callback = train_utils.StreamlitKerasCallback(epochs, train_progress, train_status)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)

    history = model.fit(
        X_train, y_train_mapped,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(X_test, y_test_mapped),
        callbacks=[EarlyStopping(patience=10, restore_best_weights=True), reduce_lr, st_callback],
        verbose=0
    )
    
    st.success("è®­ç»ƒå®Œæˆï¼")
    
    # --- D. ç»“æœå¯è§†åŒ– ---
    col1, col2 = st.columns(2)
    with col1:
        fig, ax = plt.subplots()
        ax.plot(history.history['accuracy'], label='Train')
        ax.plot(history.history['val_accuracy'], label='Val')
        ax.set_title("Accuracy")
        ax.legend()
        st.pyplot(fig)
    with col2:
        fig, ax = plt.subplots()
        ax.plot(history.history['loss'], label='Train')
        ax.plot(history.history['val_loss'], label='Val')
        ax.set_title("Loss")
        ax.legend()
        st.pyplot(fig)
    
    # æŠ•ç¥¨æ¨¡æ‹Ÿé€»è¾‘
    y_pred = np.argmax(model.predict(X_test), axis=1)
    test_groups = groups[test_idx]
    
    voting_results = {}
    for i, g in enumerate(test_groups):
        if g not in voting_results: voting_results[g] = {'true': y_test_mapped[i], 'preds': []}
        voting_results[g]['preds'].append(y_pred[i])
        
    correct = sum(1 for res in voting_results.values() 
                  if np.argmax(np.bincount(res['preds'], minlength=num_classes)) == res['true'])
    segment_acc = correct / len(voting_results) if voting_results else 0
    
    _, win_acc = model.evaluate(X_test, y_test_mapped, verbose=0)
    st.metric("Segment Level Accuracy (Voting)", f"{segment_acc*100:.2f}%", delta=f"Window Acc: {win_acc*100:.2f}%")

    st.session_state['trained_model'] = model

# --- E. æ¨¡å‹ä¿å­˜ ---
if st.session_state['trained_model']:
    st.markdown("---")
    c1, c2 = st.columns(2)
    save_name = c1.text_input("ä¿å­˜æ–‡ä»¶å", "my_model.h5")
    if c2.button("ä¿å­˜æ¨¡å‹"):
        st.session_state['trained_model'].save(save_name)
        st.success(f"å·²ä¿å­˜è‡³ {save_name}")

elif run_btn and not target_files:
    st.warning("è¯·é€‰æ‹©æ•°æ®ï¼")