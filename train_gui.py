import streamlit as st
import os
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# --- æ¨¡å—å¯¼å…¥ ---
import data_loader
import train_utils  # æ–°å¯¼å…¥
import ui_helper    # æ–°å¯¼å…¥
from model import build_simple_cnn, build_advanced_crnn

# ================= 0. å…¨å±€è®¾ç½® =================
# è·å– GPU è®¾ç½® (è¿™æ®µä»£ç æœ€å¥½æ”¾åœ¨æœ€å‰é¢)
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

st.set_page_config(layout="wide", page_title="EMG è®­ç»ƒå·¥ä½œç«™")

# åˆå§‹åŒ– Session State
if 'trained_model' not in st.session_state:
    st.session_state['trained_model'] = None

# ================= 1. ä¾§è¾¹æ é…ç½® =================
st.sidebar.header("ğŸš€ è®­ç»ƒæ¨¡å¼")
train_mode = st.sidebar.radio("é€‰æ‹©æ¨¡å¼", ["ä»é›¶å¼€å§‹è®­ç»ƒ", "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)"])

base_model_path = None
if train_mode == "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)":
    base_model_path = st.sidebar.file_uploader("ä¸Šä¼ åŸºæ¨¡å‹ (.h5)", type=["h5"])
    num_finetune_samples = st.sidebar.slider("æ¯ä¸ªç±»åˆ«ç”¨äºå¾®è°ƒçš„æ ·æœ¬æ•°", 1, 10, 5)

with st.sidebar:
    st.header("1. æ•°æ®é€‰æ‹©")
    DATA_ROOT = "data"
    
    if not os.path.exists(DATA_ROOT):
        st.error(f"æœªæ‰¾åˆ° {DATA_ROOT} æ–‡ä»¶å¤¹")
        st.stop()
        
    # è°ƒç”¨ ui_helper æ‰«ææ–‡ä»¶
    structure, file_map = ui_helper.scan_data_folder(DATA_ROOT)
    
    # --- çº§è”é€‰æ‹©å™¨ (è°ƒç”¨ ui_helper) ---
    all_subjects = sorted(structure.keys())
    selected_subjects = ui_helper.render_multiselect_with_all(
        "é€‰æ‹©æµ‹è¯•è€… (Subjects)", all_subjects, 'selected_subjects_key', default_first=True
    )
    
    available_dates = set()
    for s in selected_subjects:
        if s in structure: available_dates.update(structure[s].keys())
    selected_dates = ui_helper.render_multiselect_with_all(
        "é€‰æ‹©æ—¥æœŸ (Dates)", sorted(list(available_dates)), 'selected_dates_key', default_first=True
    )
    
    available_labels = set()
    for s in selected_subjects:
        for d in selected_dates:
            if s in structure and d in structure[s]: available_labels.update(structure[s][d])
    selected_labels = ui_helper.render_multiselect_with_all(
        "é€‰æ‹©åŠ¨ä½œ ID (Labels)", sorted(list(available_labels)), 'selected_labels_key', default_first=True
    )

    st.markdown("---")
    
    # ç»Ÿè®¡é€‰ä¸­æ–‡ä»¶
    target_files = []
    for s in selected_subjects:
        for d in selected_dates:
            for l in selected_labels:
                key = (s, d, l)
                if key in file_map: target_files.extend(file_map[key])
    
    st.info(f"å·²é€‰ä¸­ **{len(target_files)}** ä¸ª CSV æ–‡ä»¶")

    st.header("2. å¢å¼ºä¸è®­ç»ƒé…ç½®")
    
    with st.expander("æ•°æ®å¢å¼ºä¸é‡‡æ ·", expanded=True):
        train_stride_ms = st.slider("åˆ‡ç‰‡æ­¥é•¿ (Stride ms)", 10, 200, 100)
        
        st.markdown("---")
        st.caption("è´Ÿæ ·æœ¬ç­–ç•¥")
        enable_rest = st.checkbox("åŠ å…¥é™æ¯ç±» (Rest, Label 0)", value=True)
        
        st.markdown("---")

        st.caption("å¢å¼ºç­–ç•¥")
        c1, c2 = st.columns(2)
        enable_scaling = c1.checkbox("å¹…åº¦ç¼©æ”¾", value=True)
        enable_noise = c2.checkbox("é«˜æ–¯å™ªå£°", value=True)
        enable_warp = c1.checkbox("æ—¶é—´æ‰­æ›² (Warp)", value=False, help="æ¨¡æ‹ŸåŠ¨ä½œå¿«æ…¢å˜åŒ–")
        enable_shift = c2.checkbox("æ—¶é—´å¹³ç§» (Shift)", value=False, help="æ¨¡æ‹Ÿè§¦å‘æ—¶æœºåç§»")
        enable_mask = st.checkbox("é€šé“é®æŒ¡ (Channel Mask)", value=False, help="æ¨¡æ‹ŸæŸä¸ªä¼ æ„Ÿå™¨æ¥è§¦ä¸è‰¯ï¼Œæå‡é²æ£’æ€§")
        
        # === æ–°å¢å€å¢ç³»æ•° ===
        aug_multiplier = 1
        if train_mode == "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)":
            st.markdown("---")
            aug_multiplier = st.slider("æ ·æœ¬å€å¢ç³»æ•° (Multiplier)", 1, 50, 20, 
                                     help="å°†æ¯ä¸ªæ ·æœ¬å˜æˆ N ä¸ªï¼Œ20ä¸ªæ ·æœ¬ -> 400ä¸ªè®­ç»ƒæ•°æ®")
        
        augment_config = {
            'enable_rest': enable_rest,
            'multiplier': aug_multiplier,
            'enable_scaling': enable_scaling, 
            'enable_noise': enable_noise,
            'enable_warp': enable_warp,
            'enable_shift': enable_shift,
            'enable_mask': enable_mask
        }
        
    st.markdown("---")
    model_type = st.selectbox("é€‰æ‹©æ¨¡å‹æ ¸å¿ƒ", ["Lite: Simple CNN", "Pro: Multi-Scale CRNN"])

    split_mode = st.radio("éªŒè¯ç­–ç•¥", ("1. æ··åˆåˆ‡åˆ†", "2. ç•™æ–‡ä»¶éªŒè¯", "3. ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯"))
    
    strategy_map = {
        "1. æ··åˆåˆ‡åˆ†": "æ··åˆåˆ‡åˆ† (çœ‹åˆ°æ‰€æœ‰å¤©/äºº)",
        "2. ç•™æ–‡ä»¶éªŒè¯": "ç•™æ–‡ä»¶éªŒè¯ (åŒå¤©/åŒäºº)",
        "3. ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯": "ç•™æ—¥æœŸ/å¯¹è±¡éªŒè¯ (æ³›åŒ–èƒ½åŠ›)"
    }
    selected_strategy = strategy_map[split_mode]

    manual_val_target = None
    if "ç•™æ–‡ä»¶" in selected_strategy and target_files:
        file_options = sorted(list(set([os.path.basename(f) for f in target_files])))
        manual_val_target = st.selectbox("ğŸ¯ æŒ‡å®šæµ‹è¯•æ–‡ä»¶", file_options)
    elif "ç•™æ—¥æœŸ" in selected_strategy and target_files:
        group_options = sorted(list(set([os.path.basename(os.path.dirname(f)) for f in target_files])))
        manual_val_target = st.selectbox("ğŸ¯ æŒ‡å®šæµ‹è¯•å¯¹è±¡/æ—¥æœŸ", group_options)

    st.markdown("---") 
    epochs = st.number_input("Epochs", 10, 200, 50)
    batch_size = st.selectbox("Batch Size", [16, 32, 64, 128], index=1)
    test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.01, 0.5, 0.2)
    
    run_btn = st.button("ğŸš€ å¼€å§‹å¤„ç†å¹¶è®­ç»ƒ", type="primary")

# ================= 2. ä¸»é€»è¾‘åŒºåŸŸ =================
st.title("ğŸ§  EMG äº¤äº’å¼è®­ç»ƒç³»ç»Ÿ")

if run_btn and target_files:
    # --- A. æ•°æ®å¤„ç† ---
    st.subheader("1. æ•°æ®é¢„å¤„ç†")
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    X, y, groups = data_loader.process_selected_files(
        target_files, 
        progress_callback=lambda p, t: (progress_bar.progress(p), status_text.text(t)),
        stride_ms=train_stride_ms,
        augment_config=augment_config
    )
    
    status_text.text("å¤„ç†å®Œæˆï¼")
    progress_bar.progress(100)
    
    if len(X) == 0:
        st.error("æ ·æœ¬æ•°ä¸º 0ï¼Œè¯·æ£€æŸ¥æ•°æ®ã€‚")
        st.stop()
        
    st.success(f"X={X.shape}, y={y.shape} | ç±»åˆ«: {np.unique(y)}")
    
    # --- B. æ¨¡å‹è®­ç»ƒå‡†å¤‡ ---
    st.subheader("2. æ¨¡å‹è®­ç»ƒ")
    
    # åˆ’åˆ†æ•°æ®é›† (è°ƒç”¨ train_utils)
    if train_mode == "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)":
        train_idx, test_idx = train_utils.get_few_shot_split(X, y, num_finetune_samples)
    else:
        train_idx, test_idx = train_utils.smart_split(
            X, y, groups, selected_strategy, test_size, manual_target=manual_val_target
        )

    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    
    # æ ‡ç­¾æ˜ å°„
    unique_labels = np.unique(y)
    num_classes = len(unique_labels) 
    label_map = {original: new for new, original in enumerate(unique_labels)}
    y_train_mapped = np.array([label_map[i] for i in y_train])
    y_test_mapped = np.array([label_map[i] for i in y_test])

    # æ„å»ºæ¨¡å‹
    if train_mode == "åŸºäºåŸºæ¨¡å‹å¾®è°ƒ (Few-shot)":
        if base_model_path:
            # 1. ä¿å­˜å¹¶åŠ è½½ä¸Šä¼ çš„åŸºæ¨¡å‹
            with open("temp_model.h5", "wb") as f: f.write(base_model_path.getbuffer())
            base_model = tf.keras.models.load_model("temp_model.h5")
            
            # 2. å†»ç»“åŸºæ¨¡å‹çš„æ‰€æœ‰å±‚
            # æ„å‘³ç€åœ¨åå‘ä¼ æ’­æ—¶ï¼Œè¿™äº›å±‚çš„æƒé‡ç»å¯¹ä¸ä¼šæ›´æ–°ï¼Œä¿æŠ¤å®ƒä»¬å­¦åˆ°çš„é€šç”¨ç‰¹å¾
            base_model.trainable = False 
            
            # 3. å‰¥ç¦»æ—§çš„åˆ†ç±»å¤´ï¼Œä¿ç•™ç‰¹å¾æå–éƒ¨åˆ†
            
            feature_output = None
            
            # å°è¯•è‡ªåŠ¨å¯»æ‰¾ GlobalAveragePooling å±‚
            for layer in reversed(base_model.layers):
                if "global_average_pooling" in layer.name or "flatten" in layer.name:
                    feature_output = layer.output
                    break
            
            # å¦‚æœæ‰¾ä¸åˆ°ï¼ˆæ¯”å¦‚æ˜¯è€ç‰ˆæœ¬æ¨¡å‹ï¼‰ï¼Œåˆ™å¼ºåˆ¶å–å€’æ•°ç¬¬ä¸‰å±‚çš„è¾“å‡º
            if feature_output is None:
                feature_output = base_model.layers[-3].output
            
            # 4. æ„å»ºæ›´åŠ ç¨³å¥çš„æ–°åˆ†ç±»å¤´ (Robust Head)
            x = feature_output
            
            # [å…³é”®ç‚¹ A] é«˜ Dropout: éšæœºä¸¢å¼ƒ 50% çš„ç¥ç»å…ƒï¼Œå¼ºè¿«æ¨¡å‹ä¸ä¾èµ–æŸä¸ªç‰¹å®šç‰¹å¾
            x = tf.keras.layers.Dropout(0.5)(x) 
            
            # [å…³é”®ç‚¹ B] L2 æ­£åˆ™åŒ–: æƒ©ç½šè¿‡å¤§çš„æƒé‡ï¼Œé˜²æ­¢æ¨¡å‹â€œæ­»è®°ç¡¬èƒŒâ€è¿™ 20 ä¸ªæ ·æœ¬
            x = tf.keras.layers.Dense(64, activation='relu', 
                                      kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
            
            # ç¬¬äºŒå±‚ Dropoutï¼Œè¿›ä¸€æ­¥å¢åŠ éš¾åº¦
            x = tf.keras.layers.Dropout(0.3)(x)
            
            # æœ€ç»ˆåˆ†ç±»å±‚
            outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)
            
            # ç»„åˆæˆæ–°æ¨¡å‹
            # æ³¨æ„ï¼šinputs å¿…é¡»æ¥è‡ª base_model.input
            model = tf.keras.models.Model(inputs=base_model.input, outputs=outputs)
            
            # [å…³é”®ç‚¹ C] æå°çš„å­¦ä¹ ç‡: å¾®è°ƒå¿…é¡»å°å¿ƒç¿¼ç¿¼
            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), 
                          loss='sparse_categorical_crossentropy', metrics=['accuracy'])
            
            st.success(f"âœ… å¾®è°ƒæ¨¡å‹æ„å»ºæˆåŠŸï¼\nç­–ç•¥: å†»ç»“åŸºæ¨¡å‹ + L2æ­£åˆ™åŒ– + åŒé‡Dropoutã€‚")
            
            model.summary() 
            
        else:
            st.error("è¯·ä¸Šä¼ åŸºæ¨¡å‹ (.h5 æ–‡ä»¶)")
            st.stop()
    else:
        input_shape = (X.shape[1], X.shape[2])
        if "Lite" in model_type:
            model = build_simple_cnn(input_shape, num_classes)
        else:
            model = build_advanced_crnn(input_shape, num_classes)
        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    
    # --- C. å¼€å§‹è®­ç»ƒ ---
    st.caption("è®­ç»ƒç›‘æ§")
    train_progress = st.progress(0)
    train_status = st.empty()
    
    # å®ä¾‹åŒ–å›è°ƒ (è°ƒç”¨ train_utils)
    st_callback = train_utils.StreamlitKerasCallback(epochs, train_progress, train_status)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)

    history = model.fit(
        X_train, y_train_mapped,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(X_test, y_test_mapped),
        callbacks=[EarlyStopping(patience=10, restore_best_weights=True), reduce_lr, st_callback],
        verbose=0
    )
    
    st.success("è®­ç»ƒå®Œæˆï¼")
    
    # --- D. ç»“æœå¯è§†åŒ– ---
    col1, col2 = st.columns(2)
    with col1:
        fig, ax = plt.subplots()
        ax.plot(history.history['accuracy'], label='Train')
        ax.plot(history.history['val_accuracy'], label='Val')
        ax.set_title("Accuracy")
        ax.legend()
        st.pyplot(fig)
    with col2:
        fig, ax = plt.subplots()
        ax.plot(history.history['loss'], label='Train')
        ax.plot(history.history['val_loss'], label='Val')
        ax.set_title("Loss")
        ax.legend()
        st.pyplot(fig)
    
    # æŠ•ç¥¨æ¨¡æ‹Ÿé€»è¾‘
    y_pred = np.argmax(model.predict(X_test), axis=1)
    test_groups = groups[test_idx]
    
    voting_results = {}
    for i, g in enumerate(test_groups):
        if g not in voting_results: voting_results[g] = {'true': y_test_mapped[i], 'preds': []}
        voting_results[g]['preds'].append(y_pred[i])
        
    correct = sum(1 for res in voting_results.values() 
                  if np.argmax(np.bincount(res['preds'], minlength=num_classes)) == res['true'])
    segment_acc = correct / len(voting_results) if voting_results else 0
    
    _, win_acc = model.evaluate(X_test, y_test_mapped, verbose=0)
    st.metric("Segment Level Accuracy (Voting)", f"{segment_acc*100:.2f}%", delta=f"Window Acc: {win_acc*100:.2f}%")

    st.session_state['trained_model'] = model

# --- E. æ¨¡å‹ä¿å­˜ ---
if st.session_state['trained_model']:
    st.markdown("---")
    c1, c2 = st.columns(2)
    save_name = c1.text_input("ä¿å­˜æ–‡ä»¶å", "my_model.h5")
    if c2.button("ä¿å­˜æ¨¡å‹"):
        st.session_state['trained_model'].save(save_name)
        st.success(f"å·²ä¿å­˜è‡³ {save_name}")

elif run_btn and not target_files:
    st.warning("è¯·é€‰æ‹©æ•°æ®ï¼")