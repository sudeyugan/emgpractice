import os
import sys
import time
import glob
import datetime
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.metrics import classification_report

# å¼•ç”¨ç°æœ‰æ¨¡å—
import data_loader
import train_utils
import model as model_lib  # é¿å…å˜é‡åå†²çª

# ==================== 0. é…ç½®åŒºåŸŸ (æ ¹æ®éœ€æ±‚ä¿®æ”¹) ====================

# 1. ç›®æ ‡è®¾ç½®
TARGET_SUBJECTS = ["charles", "gavvin", "gerard", "giland", "jessie", "legend"]  #åœ¨æ­¤å¤„å¡«å†™ä½ è¦æµ‹è¯•çš„â€œç‰¹å®šå‡ ä¸ªäººâ€çš„åå­—
TARGET_LABELS = [5, 6, 7, 8]            # æŒ‡å®šåŠ¨ä½œæ ‡ç­¾
TARGET_DATES = None                     # None è¡¨ç¤ºæ‰€æœ‰æ—¥æœŸï¼Œæˆ–è€…å†™ ["20250213"]

# 2. å®éªŒå˜é‡ (Grid Search)
MODELS_TO_TEST = [
    # æ ¼å¼: (æ¨¡å‹åç§°, æ„å»ºå‡½æ•°)
    ("Simple_CNN", model_lib.build_simple_cnn),
    ("Advanced_CRNN", model_lib.build_advanced_crnn),
    ("ResNet1D", model_lib.build_resnet_model),
    ("TCN", model_lib.build_tcn_model)
]

OPTIMIZERS_TO_TEST = [
    # æ ¼å¼: (åç§°, ç±»/å‡½æ•°, å­¦ä¹ ç‡, å…¶ä»–å‚æ•°)
    ("Adam", tf.keras.optimizers.Adam, 0.001, {}),
    ("AdamW", tf.keras.optimizers.AdamW, 0.001, {'weight_decay': 1e-4}),
    ("SGD", tf.keras.optimizers.SGD, 0.01, {'momentum': 0.9}),
]

VOTING_OPTIONS = [False, True] # æ˜¯å¦å¼€å¯æŠ•ç¥¨

# 3. å›ºå®šå‚æ•°
CONFIG = {
    'epochs': 100,
    'batch_size': 128,
    'stride_ms': 50,           # åˆ‡ç‰‡æ­¥é•¿ 50ms
    'test_size': 0.2,          # æµ‹è¯•é›†æ¯”ä¾‹
    'split_strategy': "æ··åˆåˆ‡åˆ† (çœ‹åˆ°æ‰€æœ‰å¤©/äºº)", 
    'label_smoothing': 0.1,    # æ ‡ç­¾å¹³æ»‘
    'voting_start_epoch': 20,  # æŠ•ç¥¨å¼€å¯æ—¶é—´
    'voting_weight': 0.5,      # æŠ•ç¥¨æƒé‡
    'samples_per_group': 5,    # æŠ•ç¥¨ç»„é‡‡æ ·æ•°
}

# 4. æ•°æ®å¢å¼ºé…ç½® (å¹…åº¦ç¼©æ”¾ + é«˜æ–¯å™ªå£°)
AUGMENT_CONFIG = {
    'enable_rest': True,       # åŠ å…¥é™æ¯
    'multiplier': 1,           # è‡ªåŠ¨åŒ–æµ‹è¯•é€šå¸¸ä¸æ— é™å€å¢ï¼Œè®¾ä¸º1æˆ–2å³å¯ï¼Œæˆ–è€…æŒ‰éœ€è°ƒæ•´
    'enable_scaling': True,    # å¹…åº¦ç¼©æ”¾
    'enable_noise': True,      # é«˜æ–¯å™ªå£°
    'enable_warp': False,
    'enable_shift': False,
    'enable_mask': False
}

LOG_DIR = "auto_train_logs"
if not os.path.exists(LOG_DIR):
    os.makedirs(LOG_DIR)

# ==================== 1. è¾…åŠ©ç±» (Mock Streamlit) ====================
# ä¸ºäº†å¤ç”¨ train_utils ä»£ç ï¼Œæˆ‘ä»¬éœ€è¦æ¨¡æ‹Ÿ Streamlit çš„è¿›åº¦æ¡å’Œæ–‡æœ¬å¯¹è±¡
class MockProgressBar:
    def progress(self, value):
        # é’ˆå¯¹ Log æ¨¡å¼çš„ä¼˜åŒ–ï¼šç›´æ¥è·³è¿‡ï¼Œä»€ä¹ˆéƒ½ä¸æ‰“å°
        # è¿™æ ·æ—¥å¿—æ–‡ä»¶é‡Œå°±ä¸ä¼šæœ‰æˆåƒä¸Šä¸‡è¡Œ "[======...]" äº†
        pass

class MockStatusText:
    def text(self, msg):
        # å°†å…³é”®ä¿¡æ¯æ‰“å°åˆ°æ§åˆ¶å°
        print(f"    â””â”€ {msg}")

# ==================== 2. æ•°æ®åŠ è½½å‡½æ•° ====================
def find_target_files(data_root="data"):
    target_files = []
    # éå†æ‰€æœ‰å±‚çº§å¯»æ‰¾ RAW_EMG
    pattern = os.path.join(data_root, "*", "*", "RAW_EMG*.csv")
    all_files = glob.glob(pattern)
    
    print(f"ğŸ” æ‰«æä¸­... å…±å‘ç° {len(all_files)} ä¸ªæ–‡ä»¶ï¼Œæ­£åœ¨ç­›é€‰...")
    
    for f in all_files:
        subject, date, label, fname = data_loader.parse_filename_info(f)
        
        # ç­›é€‰é€»è¾‘
        if subject not in TARGET_SUBJECTS: continue
        if TARGET_DATES and date not in TARGET_DATES: continue
        if label not in TARGET_LABELS: continue
        
        target_files.append(f)
        
    return sorted(target_files)

# ==================== 3. æ ¸å¿ƒè®­ç»ƒå¾ªç¯ ====================
def run_automation():
    # 1. å‡†å¤‡æ•°æ®
    files = find_target_files()
    if not files:
        print("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œé…ç½®ã€‚")
        return

    print(f"âœ… é€‰ä¸­æ–‡ä»¶æ•°: {len(files)}")
    print("â³ æ­£åœ¨é¢„å¤„ç†æ•°æ® (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
    
    # æ¨¡æ‹Ÿè¿›åº¦æ¡
    mock_bar = MockProgressBar()
    mock_status = MockStatusText()
    
    # åŠ è½½æ•°æ® (åªåŠ è½½ä¸€æ¬¡ï¼ŒèŠ‚çœæ—¶é—´)
    X, y, groups = data_loader.process_selected_files(
        files, 
        progress_callback=lambda p, t: None, # é¢„å¤„ç†æ—¶ä¸åˆ·å±
        stride_ms=CONFIG['stride_ms'],
        augment_config=AUGMENT_CONFIG
    )
    
    if len(X) == 0:
        print("âŒ ç”Ÿæˆæ ·æœ¬æ•°ä¸º 0ï¼Œé€€å‡ºã€‚")
        return
        
    print(f"\nğŸ“Š æ•°æ®å‡†å¤‡å°±ç»ª: X={X.shape}, y={y.shape}, Classes={np.unique(y)}")
    
    # åˆ‡åˆ†æ•°æ®
    train_idx, test_idx = train_utils.smart_split(
        X, y, groups, CONFIG['split_strategy'], test_size=CONFIG['test_size']
    )
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    groups_train = groups[train_idx]
    
    # æ˜ å°„æ ‡ç­¾ (ç¡®ä¿æ˜¯ 0, 1, 2, 3...)
    unique_labels = np.unique(y)
    num_classes = len(unique_labels)
    label_map = {original: new for new, original in enumerate(unique_labels)}
    y_train_mapped = np.array([label_map[i] for i in y_train])
    y_test_mapped = np.array([label_map[i] for i in y_test])
    
    input_shape = (X.shape[1], X.shape[2])

    MODELS_DIR = "trained_models"  # [NEW]
    if not os.path.exists(MODELS_DIR):
        os.makedirs(MODELS_DIR)
    
    # 2. å¾ªç¯å®éªŒ
    total_experiments = len(MODELS_TO_TEST) * len(OPTIMIZERS_TO_TEST) * len(VOTING_OPTIONS)
    current_exp = 0
    
    for model_name, model_builder in MODELS_TO_TEST:
        for opt_name, opt_class, lr, opt_params in OPTIMIZERS_TO_TEST:
            for use_voting in VOTING_OPTIONS:
                current_exp += 1
                exp_id = f"{model_name}_{opt_name}_Vote{use_voting}"
                print(f"\n\nğŸš€ [{current_exp}/{total_experiments}] å¼€å§‹å®éªŒ: {exp_id}")
                print("-" * 50)
                
                # æ„å»ºæ¨¡å‹
                tf.keras.backend.clear_session() # æ¸…ç†å†…å­˜
                model = model_builder(input_shape, num_classes)
                
                # æ„å»ºä¼˜åŒ–å™¨
                try:
                    optimizer = opt_class(learning_rate=lr, **opt_params)
                except Exception as e:
                    print(f"ä¼˜åŒ–å™¨åˆå§‹åŒ–å¤±è´¥: {e}, è·³è¿‡ã€‚")
                    continue
                
                # è®­ç»ƒ
                start_time = time.time()
                try:
                    history_dict = train_utils.train_with_voting_mechanism(
                        model, 
                        X_train, y_train_mapped, groups_train,
                        X_test, y_test_mapped,
                        epochs=CONFIG['epochs'],
                        batch_size=CONFIG['batch_size'],
                        samples_per_group=CONFIG['samples_per_group'],
                        vote_weight=CONFIG['voting_weight'] if use_voting else 0.0,
                        st_progress_bar=mock_bar,
                        st_status_text=mock_status,
                        use_mixup=False, # è‡ªåŠ¨åŒ–è„šæœ¬æš‚ä¸å¼€å¯Mixupä»¥ä¿æŒç®€å•ï¼Œå¯æŒ‰éœ€å¼€å¯
                        label_smoothing=CONFIG['label_smoothing'],
                        voting_start_epoch=CONFIG['voting_start_epoch'] if use_voting else 0,
                        optimizer=optimizer
                    )
                except Exception as e:
                    print(f"\nâŒ è®­ç»ƒå´©æºƒ: {e}")
                    import traceback
                    traceback.print_exc()
                    continue
                    
                duration = time.time() - start_time
                
                save_name = f"{exp_id}.keras" # TF 2.10+ æ¨è .kerasï¼Œæ—§ç‰ˆå¯ç”¨ .h5
                save_path = os.path.join(MODELS_DIR, save_name)
                
                try:
                    model.save(save_path)
                    print(f"    ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³: {save_path}")
                except Exception as e:
                    print(f"    âš ï¸ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")

                # 3. è¯„ä¼°ä¸æ—¥å¿—ä¿å­˜
                save_log(exp_id, model, history_dict, X_test, y_test_mapped, 
                         label_map, duration, opt_name, lr, use_voting)

def save_log(exp_id, model, history, X_test, y_test, label_map, duration, opt_name, lr, use_voting):
    # è®¡ç®—é¢„æµ‹
    y_pred_probs = model.predict(X_test, verbose=0)
    y_pred = np.argmax(y_pred_probs, axis=1)
    
    # ç”ŸæˆæŠ¥å‘Š
    report_dict = classification_report(
        y_test, y_pred, 
        target_names=[str(k) for k in label_map.keys()], 
        output_dict=True
    )
    report_df = pd.DataFrame(report_dict).transpose()
    
    # æ–‡ä»¶å
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M")
    filename = os.path.join(LOG_DIR, f"{timestamp}_{exp_id}.txt")
    
    final_acc = history['val_accuracy'][-1]
    final_loss = history['val_loss'][-1]
    
    with open(filename, "w", encoding="utf-8") as f:
        f.write(f"Experiment ID: {exp_id}\n")
        f.write(f"Date: {timestamp}\n")
        f.write(f"Duration: {duration:.1f} seconds\n")
        f.write("="*40 + "\n")
        f.write(f"Subjects: {TARGET_SUBJECTS}\n")
        f.write(f"Labels: {TARGET_LABELS}\n")
        f.write(f"Model: {model.name}\n")
        f.write(f"Optimizer: {opt_name} (LR={lr})\n")
        f.write(f"Voting Mode: {'ON' if use_voting else 'OFF'}")
        if use_voting:
            f.write(f" (Start Epoch: {CONFIG['voting_start_epoch']})\n")
        else:
            f.write("\n")
        f.write("-" * 20 + "\n")
        f.write(f"Epochs: {CONFIG['epochs']}\n")
        f.write(f"Batch Size: {CONFIG['batch_size']}\n")
        f.write(f"Augment: {AUGMENT_CONFIG}\n")
        f.write("="*40 + "\n")
        f.write(f"Final Val Accuracy: {final_acc*100:.2f}%\n")
        f.write(f"Final Val Loss: {final_loss:.4f}\n")
        f.write("\n--- Classification Report ---\n")
        f.write(report_df.to_string())
        
    print(f"\nğŸ’¾ æ—¥å¿—å·²ä¿å­˜: {filename}")

if __name__ == "__main__":
    # è®¾ç½® GPU æ˜¾å­˜å¢é•¿ï¼Œé˜²æ­¢ OOM
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except RuntimeError as e:
            print(e)
            
    run_automation()